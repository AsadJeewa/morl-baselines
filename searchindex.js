Search.setIndex({"docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/envelope", "algos/multi_policy/gpi_pd", "algos/multi_policy/linear_support", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pgmorl", "algos/performances", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "index", "quickstart/overview"], "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/envelope.md", "algos/multi_policy/gpi_pd.md", "algos/multi_policy/linear_support.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pgmorl.md", "algos/performances.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "index.md", "quickstart/overview.md"], "titles": ["Overview", "Multi-Policy Algorithms", "Envelope Q-Learning", "GPI-Prioritized Dyna", "Linear Support", "MPMOQ Learning", "Pareto Q-Learning", "PGMORL", "Performance assessments", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "terms": {"morl": [0, 2, 3, 5, 6, 7, 8, 10, 11, 12, 14, 17, 20], "baselin": [0, 2, 3, 5, 6, 7, 10, 11, 12, 14, 20], "contain": [0, 13, 14, 19, 20], "multipl": [0, 2, 13], "implement": [0, 4, 8, 12, 13, 19, 20], "multi": [0, 2, 3, 5, 6, 7, 10, 11, 15, 17, 20], "object": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 17], "reinforc": [0, 2, 5, 6, 7, 8, 10, 11, 13, 15], "learn": [0, 3, 7, 8, 10, 12, 13, 15], "algorithm": [0, 2, 3, 4, 5, 7, 10, 11, 12, 13, 17, 20], "The": [0, 2, 6, 8, 10, 13, 14, 15, 16, 20], "follow": [0, 8, 13, 14, 15, 19, 20], "tabl": [0, 11], "list": [0, 2, 3, 4, 7, 10, 13, 14, 15, 17], "ar": [0, 4, 8, 12, 13, 14, 17, 19], "current": [0, 2, 4, 6, 12, 13, 14, 15, 17], "algo": [0, 4], "singl": [0, 11, 19, 20], "polici": [0, 2, 3, 4, 5, 6, 10, 11, 17, 19, 20], "esr": [0, 10, 13, 19, 20], "ser": [0, 11, 19, 20], "observ": [0, 2, 10, 13, 15], "space": 0, "action": [0, 2, 3, 6, 10, 11, 13], "paper": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 15, 17, 19], "gpi": [0, 4, 8], "pd": [0, 3, 8], "continu": [0, 7, 8], "discret": [0, 8], "envelop": [0, 8], "q": [0, 5, 8, 11, 12], "pgmorl": [0, 8, 17], "supplementari": [0, 7], "materi": [0, 7], "pareto": [0, 8, 12, 17, 19], "mo": [0, 5, 7, 8, 11, 19, 20], "mpmoqlearn": [0, 5, 8], "outer": [0, 5], "loop": [0, 5], "moql": 0, "optimist": [0, 4], "linear": 0, "support": [0, 3, 8], "ol": [0, 4, 8], "section": [0, 4], "3": [0, 4, 8], "thesi": [0, 4], "expect": [0, 8, 10, 17], "util": [0, 4, 8, 10, 11, 14, 15, 17, 19], "gradient": [0, 10], "eupg": [0, 8, 12], "warn": [0, 8], "have": [0, 8, 12, 14, 16, 19], "been": [0, 14, 16, 19], "benchmark": 0, "yet": 0, "some": [0, 8, 17], "them": [0, 8, 12], "limit": 0, "featur": [0, 12, 15], "For": [0, 8, 19], "exampl": [0, 20], "i": [0, 2, 4, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20], "2": [0, 3, 7, 8, 13], "class": [2, 3, 4, 5, 6, 7, 10, 11, 13, 15, 16], "morl_baselin": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19], "multi_polici": [2, 3, 4, 5, 6, 7, 20], "env": [2, 3, 4, 5, 6, 7, 10, 11, 14], "learning_r": [2, 3, 5, 7, 10, 11], "float": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 17, 18], "0": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15], "0003": [2, 3, 7], "initial_epsilon": [2, 3, 5, 6, 11], "01": [2, 3, 13, 14], "final_epsilon": [2, 3, 5, 6, 11], "epsilon_decay_step": [2, 3, 5, 11], "option": [2, 3, 4, 5, 6, 7, 10, 11, 14], "int": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 17, 18], "none": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14], "tau": [2, 3, 14, 18], "1": [2, 3, 4, 5, 6, 7, 8, 11, 13, 14], "target_net_update_freq": [2, 3], "1000": [2, 3, 5, 10, 11], "buffer_s": [2, 3, 10], "1000000": [2, 3], "net_arch": [2, 3, 7, 10, 15], "256": [2, 3], "batch_siz": [2, 3, 13], "learning_start": [2, 3, 5, 11], "100": [2, 3, 6, 7], "gradient_upd": [2, 3], "gamma": [2, 3, 5, 6, 7, 10, 11], "99": [2, 3, 6, 10], "max_grad_norm": [2, 3, 7], "bool": [2, 3, 4, 5, 6, 7, 10, 11, 13, 15, 17], "true": [2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 17], "num_sample_w": 2, "4": [2, 7], "per": [2, 3, 6, 11, 15], "per_alpha": 2, "6": [2, 3, 7], "initial_homotopy_lambda": 2, "final_homotopy_lambda": 2, "homotopy_decay_step": 2, "project_nam": [2, 3, 5, 6, 7, 10, 11], "str": [2, 3, 4, 5, 6, 7, 10, 11, 14, 17], "experiment_nam": [2, 3, 5, 6, 7, 10, 11], "log": [2, 3, 5, 6, 7, 10, 11, 14], "devic": [2, 3, 7, 10, 13], "union": [2, 3, 7, 10, 17], "auto": [2, 3, 7, 10], "lean": 2, "us": [2, 3, 4, 6, 8, 10, 11, 13, 14, 15, 17, 20], "condit": [2, 10], "network": [2, 3, 10, 14], "emb": 2, "take": 2, "weight": [2, 3, 4, 8, 10, 11, 14, 17, 18, 19], "input": [2, 14, 15, 16], "main": [2, 12, 13], "chang": [2, 3, 16], "thi": [2, 8, 12, 13, 14, 15, 16, 18, 19, 20], "compar": [2, 8], "scalar": [2, 4, 5, 8, 10, 11, 14], "cn": 2, "dqn": [2, 14, 15], "target": [2, 13, 14], "updat": [2, 3, 10, 11, 13, 14], "r": [2, 17], "yang": 2, "x": [2, 14], "sun": 2, "k": [2, 5, 6, 11], "narasimhan": 2, "A": [2, 5, 6, 8, 10, 11, 13, 14, 17], "gener": [2, 3, 4, 5, 7, 8, 10, 11, 14], "adapt": [2, 18], "arxiv": [2, 3, 4], "1908": 2, "08342": 2, "c": [2, 3, 8], "nov": [2, 7, 8], "2019": 2, "access": 2, "sep": 2, "06": 2, "2021": 2, "onlin": 2, "avail": [2, 7, 8, 13, 19], "http": [2, 3, 4, 7, 8, 13, 16, 19], "org": [2, 3, 4], "ab": [2, 3, 4], "act": 2, "ob": [2, 3, 4, 10, 11, 13], "tensor": [2, 3, 13, 14, 15], "w": [2, 3, 4, 7, 8, 10, 11], "epsilon": [2, 4, 14], "greedili": [2, 11], "select": [2, 3, 6], "an": [2, 3, 4, 6, 8, 12, 14, 15], "given": [2, 3, 6, 10, 13, 14], "paramet": [2, 3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 19], "vector": [2, 3, 4, 6, 14, 15, 16, 17, 18], "return": [2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19], "integ": 2, "repres": [2, 15], "ddqn_target": 2, "doubl": 2, "envelope_target": 2, "sampled_w": 2, "comput": [2, 4, 6, 8, 13, 14, 17], "set": [2, 3, 4, 6, 13, 16, 17, 20], "sampl": [2, 3, 13], "eval": [2, 3, 10, 11], "ndarrai": [2, 3, 4, 5, 6, 7, 10, 11, 14, 15, 16, 17, 18], "give": [2, 10, 13], "best": [2, 10, 11, 18], "np": [2, 3, 4, 10, 17], "arrai": [2, 7, 10, 11, 13, 19], "get_config": [2, 3, 5, 6, 7, 10, 11], "dictionari": [2, 5, 6, 7, 10, 11, 13, 14], "configur": [2, 3, 5, 6, 7, 10, 11], "dict": [2, 5, 6, 7, 10, 11, 14], "config": [2, 5, 7, 10, 11], "load": [2, 3], "path": [2, 3], "load_replay_buff": [2, 3], "model": [2, 3], "replai": [2, 3, 20], "buffer": [2, 3, 10, 19, 20], "specifi": [2, 13], "whether": [2, 3, 11, 13, 15], "too": 2, "max_act": [2, 3], "highest": [2, 4], "valu": [2, 4, 6, 8, 13, 14, 17, 18], "save": [2, 3, 14], "save_replay_buff": [2, 3], "save_dir": [2, 3], "filenam": [2, 3], "directori": 2, "train": [2, 3, 5, 6, 7, 10, 11, 14], "total_timestep": [2, 3, 10, 11], "total_episod": [2, 3], "reset_num_timestep": [2, 3, 11], "eval_env": [2, 3, 10, 11], "eval_freq": [2, 3, 5, 10, 11], "reset_learning_start": [2, 3], "fals": [2, 3, 4, 7, 13, 15], "agent": [2, 3, 4, 5, 7, 8, 10, 11, 14], "total": 2, "number": [2, 3, 4, 6, 10, 11, 13, 14, 15], "timestep": [2, 3, 10, 11, 14], "If": [2, 4, 12, 13], "randomli": 2, "everi": [2, 6], "episod": [2, 3, 6, 10, 14], "done": [2, 13], "ignor": 2, "reset": [2, 3, 11], "when": [2, 4, 11, 13], "time": [2, 4, 11], "environ": [2, 3, 4, 8, 10, 11, 19, 20], "evalu": [2, 3, 4, 5, 6, 10, 11, 16], "frequenc": [2, 10], "start": [2, 3, 11, 13], "": [2, 7, 8, 10, 13, 14, 19, 20], "e": [2, 10, 13, 17, 19], "g": [2, 10, 17, 19], "experi": [2, 10, 13, 19], "from": [2, 4, 6, 8, 10, 12, 13, 14, 15, 17, 19], "gpi_pd": 3, "gpipd": 3, "type": [3, 5, 11, 15, 17], "num_net": 3, "use_gpi": 3, "alpha_p": 3, "min_prior": [3, 13, 14], "drop_rat": [3, 15], "layer_norm": [3, 15], "dynamics_normalize_input": 3, "dynamics_uncertainty_threshold": 3, "5": [3, 7, 11], "dynamics_train_freq": 3, "callabl": [3, 6, 17, 18], "function": [3, 4, 5, 6, 8, 11, 13, 14, 15, 16, 17, 19], "lambda": [3, 13], "dynamics_rollout_len": 3, "dynamics_rollout_start": 3, "5000": 3, "dynamics_rollout_freq": 3, "250": 3, "dynamics_rollout_batch_s": 3, "10000": 3, "dynamics_buffer_s": 3, "400000": 3, "dynamics_net_arch": 3, "200": 3, "dynamics_ensemble_s": 3, "dynamics_num_elit": 3, "real_ratio": 3, "05": [3, 13], "torch": [3, 11, 14, 15], "effici": 3, "via": 3, "improv": [3, 4], "luca": [3, 12, 19], "n": [3, 12, 13, 14, 19], "alegr": [3, 12, 19], "ana": 3, "l": [3, 4, 8, 17], "bazzan": 3, "diederik": 3, "m": [3, 5, 8, 11, 17], "roijer": [3, 4, 8, 10, 17], "ann": 3, "now\u00e9": [3, 6], "bruno": 3, "da": 3, "silva": 3, "aama": 3, "2023": 3, "2301": [3, 4], "07784": [3, 4], "gpi_act": 3, "return_policy_index": 3, "include_w": 3, "greedi": [3, 11], "set_weight_support": 3, "weight_list": 3, "weight_support": 3, "change_w_every_episod": 3, "method": [3, 6, 8, 11, 13, 14], "end": [3, 4, 13], "each": [3, 8, 11, 13, 15, 17, 18], "gym": 3, "between": [3, 8, 11, 17], "linear_support": 4, "linearsupport": 4, "num_object": 4, "verbos": 4, "corner": 4, "both": [4, 8, 19], "info": [4, 14], "pub": 4, "pdf": [4, 7], "add_solut": 4, "add": [4, 13, 16], "new": [4, 12, 13], "optim": [4, 6, 8, 19], "indic": [4, 13], "remov": [4, 13, 16], "cc": [4, 8], "being": 4, "domin": [4, 6, 16, 18], "compute_corner_weight": 4, "see": [4, 20], "definit": [4, 19], "19": 4, "typo": 4, "sign": 4, "should": [4, 13], "queue": 4, "empti": 4, "get_corner_weight": 4, "top_k": 4, "get_weight_support": 4, "gpi_ls_prior": 4, "gpi_expanded_set": 4, "get": [4, 6, 12, 13], "prioriti": [4, 13, 14], "is_domin": 4, "check": [4, 13], "ani": [4, 17], "otherwis": 4, "max_scalarized_valu": 4, "maximum": [4, 8, 13, 17], "max_value_lp": 4, "w_new": 4, "upper": 4, "bound": 4, "next_weight": 4, "gpi_ag": 4, "mopolici": 4, "rep_ev": 4, "next": [4, 13], "either": [4, 14], "ols_prior": 4, "remove_obsolete_valu": 4, "which": [4, 8, 13, 14, 15, 19], "all": [4, 5, 8, 12, 13, 16, 19, 20], "visit": 4, "remove_obsolete_weight": 4, "new_valu": 4, "better": 4, "than": 4, "previou": [4, 13], "multi_policy_moqlearn": 5, "mp_mo_q_learn": 5, "ref_point": [5, 6, 7, 17], "numpi": [5, 11, 13, 17, 18, 19], "weights_step_s": 5, "weighted_sum": [5, 11, 18], "9": [5, 11], "num_timestep": 5, "500000": [5, 11], "multipolici": 5, "moq": [5, 8], "version": [5, 8], "mo_q_learn": [5, 11], "van": [5, 6, 11], "moffaert": [5, 6, 11], "drugan": [5, 11], "now": [5, 10, 11], "novel": [5, 11], "design": [5, 11], "techniqu": [5, 11], "2013": [5, 11], "doi": [5, 8, 11], "10": [5, 7, 8, 11], "1109": [5, 11], "adprl": [5, 11], "6615007": [5, 11], "eval_all_ag": 5, "reward": [5, 8, 10, 18, 19], "discount": 5, "tupl": [5, 13], "pareto_q_learn": 6, "pql": 6, "8": 6, "epsilon_decai": 6, "seed": [6, 7, 8, 14], "tabular": 6, "reli": [6, 8, 11, 17, 18], "prune": [6, 19], "journal": [6, 19], "machin": [6, 7, 8], "research": 6, "vol": [6, 8], "15": 6, "pp": [6, 7, 8], "3483": 6, "3512": 6, "2014": 6, "calc_non_domin": 6, "state": 6, "non": [6, 16], "get_local_pc": 6, "collect": [6, 15], "local": 6, "pc": 6, "default": [6, 13, 17], "get_q_set": 6, "pair": [6, 13], "score_hypervolum": 6, "score": 6, "base": [6, 8, 10, 17], "upon": 6, "hypervolum": [6, 8, 17], "metric": [6, 17], "score_pareto_cardin": 6, "cardin": 6, "select_act": 6, "score_func": 6, "track_polici": 6, "vec": 6, "track": 6, "its": [6, 13], "array_lik": 6, "num_episod": 6, "3000": 6, "log_everi": 6, "action_ev": 6, "front": [6, 8, 16, 17], "result": 6, "name": 6, "final": [6, 14], "env_id": 7, "halfcheetah": 7, "v4": 7, "num_env": 7, "pop_siz": 7, "warmup_iter": 7, "80": 7, "steps_per_iter": 7, "2048": 7, "limit_env_step": 7, "5000000": 7, "evolutionary_iter": 7, "20": 7, "num_weight_candid": 7, "7": 7, "num_performance_buff": 7, "performance_buffer_s": 7, "min_weight": 7, "max_weight": 7, "delta_weight": 7, "995": 7, "torch_determinist": 7, "64": 7, "num_minibatch": 7, "32": 7, "update_epoch": 7, "anneal_lr": 7, "clip_coef": 7, "ent_coef": 7, "vf_coef": 7, "clip_vloss": 7, "norm_adv": 7, "target_kl": 7, "gae": 7, "gae_lambda": 7, "95": 7, "predict": [7, 8, 15], "guid": [7, 8, 19], "refer": [7, 17, 18], "j": [7, 8], "xu": [7, 8], "y": [7, 8], "tian": [7, 8], "p": [7, 8, 17], "ma": [7, 8], "d": [7, 8, 10, 17], "ru": [7, 8], "sueda": [7, 8], "matusik": [7, 8], "robot": [7, 8], "control": [7, 8, 15], "proceed": [7, 8], "37th": [7, 8], "intern": [7, 8], "confer": [7, 8], "2020": [7, 8], "10607": [7, 8], "10616": [7, 8], "mlr": [7, 8], "press": [7, 8], "v119": [7, 8], "xu20h": [7, 8], "html": [7, 8], "peopl": [7, 12], "csail": 7, "mit": 7, "edu": 7, "jiex": 7, "supp": 7, "document": [8, 19, 20], "work": 8, "progress": 8, "To": 8, "ensur": 8, "correct": 8, "we": [8, 12, 13, 17, 19], "want": [8, 12], "test": [8, 19], "variou": [8, 12, 17], "sake": 8, "reproduc": 8, "run": [8, 10], "mainten": 8, "purpos": 8, "long": 8, "term": 8, "conduct": 8, "gymnasium": [8, 19, 20], "henc": 8, "abl": 8, "were": 8, "present": 8, "origin": [8, 12, 19], "propos": 8, "qualiti": [8, 17], "pf": [8, 17], "In": 8, "converg": 8, "divers": 8, "hybrid": 8, "common": [8, 13, 14, 15, 16, 17, 18, 20], "performance_ind": [8, 17], "sparsiti": [8, 17], "averag": [8, 14, 17], "distanc": [8, 13, 17], "consecut": 8, "point": [8, 16, 17, 18], "igd": [8, 17], "sota": 8, "moo": [8, 17], "literatur": 8, "It": [8, 15, 18, 19], "requir": [8, 18], "can": [8, 12], "posteriori": 8, "That": [8, 14], "do": 8, "merg": 8, "found": 8, "respect": 8, "moreov": 8, "assumpt": 8, "user": 8, "These": [8, 13], "allow": 8, "idea": [8, 10, 12], "wherea": 8, "other": [8, 11, 13, 19], "eum": [8, 17], "mul": [8, 17], "loss": [8, 14, 17], "problem": 8, "know": [8, 13], "report": [8, 19], "wandb": [8, 14], "easi": 8, "manipul": 8, "export": 8, "data": [8, 13], "below": [8, 13], "along": 8, "dst": 8, "mountaincar": 8, "fishwood": 8, "fruit": 8, "tree": [8, 13], "mario": 8, "half": 8, "cheetah": 8, "obj": 8, "hopper": 8, "note": 8, "tweak": 8, "posit": [8, 13], "onli": [8, 17, 19], "feel": 8, "modif": 8, "good": 8, "practic": [8, 19], "offici": 8, "instead": 8, "our": [8, 12], "cannot": 8, "minecart": 8, "full": [8, 13], "hay": [8, 12], "et": [8, 14, 15], "al": [8, 14, 15], "plan": [8, 19], "autonom": 8, "system": 8, "36": 8, "apr": 8, "2022": [8, 19], "1007": 8, "s10458": 8, "022": 8, "09552": 8, "zintgraf": [8, 17], "t": [8, 17], "v": [8, 17], "kanter": [8, 17], "f": [8, 12, 17], "oliehoek": [8, 17], "beau": [8, 17], "approach": [8, 17], "2015": [8, 14, 15, 17], "single_polici": [10, 11, 20], "100000": [10, 13], "50": [10, 14], "001": 10, "accru": 10, "futur": 10, "steckelmach": [10, 12], "2018": 10, "accrued_reward": [10, 13], "moqlearn": 11, "id": [11, 13, 14], "parent_writ": 11, "tensorboard": 11, "writer": [11, 14], "summarywrit": [11, 14], "maintain": 11, "one": [11, 14, 17], "choos": 11, "move": [11, 13], "start_tim": 11, "max": 11, "recal": 11, "launch": 11, "discord": 12, "server": 12, "where": 12, "you": 12, "ask": 12, "question": [12, 16], "help": 12, "repositori": [12, 19], "join": 12, "here": 12, "florian": [12, 19], "felten": [12, 19], "ffelten": 12, "lucasalegr": [12, 19], "open": 12, "alwai": [12, 18], "happi": 12, "receiv": 12, "bug": 12, "fix": 12, "discuss": 12, "your": 12, "u": 12, "also": 12, "issu": 12, "pull": 12, "request": 12, "directli": 12, "asid": 12, "contributor": 12, "mani": 12, "who": 12, "project": 12, "wai": [12, 13], "would": 12, "like": 12, "thank": 12, "willem": 12, "r\u00f6pke": 12, "hi": 12, "wilrop": 12, "deni": 12, "conor": 12, "provid": [12, 13, 16, 19], "librari": [13, 19], "replaybuff": 13, "obs_shap": 13, "action_dim": 13, "rew_dim": 13, "max_siz": 13, "obs_dtyp": 13, "float32": 13, "action_dtyp": 13, "next_ob": 13, "get_all_data": 13, "max_sampl": 13, "replac": 13, "use_c": 13, "to_tensor": 13, "batch": 13, "size": [13, 14], "cer": 13, "convert": 13, "pytorch": [13, 19], "sample_ob": 13, "diverse_buff": 13, "diversememori": 13, "main_capac": 13, "sec_capac": 13, "trace_divers": 13, "crowding_divers": 13, "value_funct": 13, "integr": 13, "secondari": 13, "code": [13, 16, 19], "extract": 13, "github": [13, 19], "com": [13, 16, 19], "axelabel": 13, "dynmorl": 13, "error": 13, "trace_id": 13, "pred_idx": 13, "tree_id": 13, "proport": 13, "same": 13, "treat": 13, "trace": 13, "determin": 13, "transit": 13, "store": 13, "identifi": 13, "relev": 13, "index": 13, "node": 13, "wa": 13, "add_sampl": 13, "write": 13, "add_tre": 13, "dupe": 13, "trg_i": 13, "src_i": 13, "copi": 13, "sourc": [13, 16], "extract_trac": 13, "those": 13, "get_data": 13, "include_indic": 13, "includ": 13, "get_error": 13, "idx": 13, "correspond": 13, "get_sec_writ": 13, "secondary_trac": 13, "reserved_idx": 13, "find": 13, "free": 13, "spot": 13, "memori": [13, 16], "recurs": 13, "past": 13, "low": 13, "crowd": 13, "get_trace_valu": 13, "trace_tupl": 13, "appli": 13, "main_mem_is_ful": 13, "becaus": 13, "circular": 13, "fill": [13, 14], "suffici": 13, "move_to_sec": 13, "span": 13, "remove_trac": 13, "whose": 13, "sec_dist": 13, "prioritized_buff": 13, "prioritizedreplaybuff": 13, "1e": 13, "update_prior": 13, "accrued_reward_buff": 13, "accruedrewardreplaybuff": 13, "action_shap": 13, "cleanup": 13, "whole": 13, "order": 13, "element": [13, 14, 16], "extrema_weight": 14, "dim": 14, "extrema": 14, "simplex": 14, "rest": 14, "get_grad_norm": 14, "param": 14, "iter": 14, "how": 14, "grad": 14, "norm": 14, "insid": 14, "nn": [14, 15], "clip_grad_norm_": 14, "huber": 14, "minimum": 14, "layer_init": 14, "layer": [14, 15], "orthogon": 14, "weight_gain": 14, "bias_const": 14, "initi": 14, "gain": 14, "constant": 14, "bia": 14, "linearly_decaying_valu": 14, "initial_valu": 14, "decay_period": 14, "step": 14, "warmup_step": 14, "final_valu": 14, "linearli": 14, "decai": 14, "natur": [14, 15], "schedul": 14, "mnih": [14, 15], "begin": 14, "until": 14, "taken": 14, "period": 14, "over": 14, "complet": 14, "so": [14, 18], "far": [14, 18], "befor": 14, "accord": 14, "log_episode_info": 14, "global_timestep": 14, "inform": 14, "last": 14, "automat": [14, 18, 19], "recordstatisticswrapp": 14, "statist": 14, "global": 14, "make_gif": 14, "fullpath": 14, "fp": 14, "length": [14, 15], "300": 14, "render": 14, "gif": 14, "polyak_upd": 14, "target_param": 14, "polyak": 14, "coeffici": 14, "usual": 14, "small": 14, "random_weight": 14, "dist": 14, "gaussian": 14, "random": 14, "normal": [14, 15], "dirichlet": 14, "distribut": 14, "alpha": 14, "naturecnn": 15, "observation_shap": 15, "features_dim": 15, "512": 15, "cnn": 15, "volodymyr": 15, "human": 15, "level": 15, "through": 15, "deep": 15, "518": 15, "7540": 15, "529": 15, "533": 15, "forward": 15, "mlp": 15, "input_dim": 15, "output_dim": 15, "activation_fn": 15, "modul": 15, "activ": 15, "relu": 15, "sequenti": 15, "creat": 15, "perceptron": 15, "fulli": 15, "connect": 15, "dimens": [15, 18], "output": 15, "architectur": 15, "net": [15, 20], "unit": 15, "after": 15, "dropout": 15, "rate": 15, "paretoarch": 16, "archiv": 16, "candid": 16, "ineffici": 16, "get_non_domin": 16, "subset": 16, "stackoverflow": 16, "32791911": 16, "fast": 16, "calcul": 16, "python": 16, "answer": 16, "wrong": 16, "import": 16, "made": [16, 17], "rl": 17, "mostli": 17, "pymoo": 17, "axiomat": 17, "hv": 17, "customli": 17, "expected_util": 17, "weights_set": 17, "dot": [17, 18], "similar": 17, "But": 17, "need": 17, "approxim": 17, "assess": 17, "product": [17, 18], "_supportsarrai": 17, "dtype": 17, "_nestedsequ": 17, "complex": 17, "byte": 17, "maximum_utility_loss": 17, "reference_set": 17, "basic": 17, "tchebicheff": 18, "reward_dim": 18, "seen": 18, "compon": 18, "sure": 18, "sum": 18, "aim": 19, "reliabl": 19, "strictli": 19, "api": 19, "differ": 19, "standard": 19, "detail": [19, 20], "mdp": 19, "momdp": 19, "suggest": 19, "read": 19, "under": 19, "criteria": 19, "perform": 19, "bias": 19, "dashboard": 19, "lint": 19, "format": 19, "enforc": 19, "pre": 19, "commit": 19, "hook": 19, "well": 19, "etc": [19, 20], "against": 19, "ones": 19, "hyper": 19, "misc": 19, "author": 19, "titl": 19, "year": 19, "publish": 19, "howpublish": 19, "url": 19, "As": 20, "much": 20, "possibl": 20, "repo": 20, "tri": 20, "file": 20, "rule": 20, "structur": 20, "recur": 20, "concept": 20, "neural": 20, "more": 20}, "objects": {"morl_baselines.common.accrued_reward_buffer": [[13, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[13, 1, 1, "", "add"], [13, 1, 1, "", "cleanup"], [13, 1, 1, "", "get_all_data"], [13, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[13, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[13, 1, 1, "", "add"], [13, 1, 1, "", "get_all_data"], [13, 1, 1, "", "sample"], [13, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[13, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[13, 1, 1, "", "add"], [13, 1, 1, "", "add_sample"], [13, 1, 1, "", "add_tree"], [13, 1, 1, "", "dupe"], [13, 1, 1, "", "extract_trace"], [13, 1, 1, "", "get"], [13, 1, 1, "", "get_data"], [13, 1, 1, "", "get_error"], [13, 1, 1, "", "get_sec_write"], [13, 1, 1, "", "get_trace_value"], [13, 1, 1, "", "main_mem_is_full"], [13, 1, 1, "", "move_to_sec"], [13, 1, 1, "", "remove_trace"], [13, 1, 1, "", "sample"], [13, 1, 1, "", "sec_distances"], [13, 1, 1, "", "update"]], "morl_baselines.common": [[15, 2, 0, "-", "networks"], [16, 2, 0, "-", "pareto"], [17, 2, 0, "-", "performance_indicators"], [18, 2, 0, "-", "scalarization"], [14, 2, 0, "-", "utils"]], "morl_baselines.common.networks": [[15, 0, 1, "", "NatureCNN"], [15, 3, 1, "", "mlp"]], "morl_baselines.common.networks.NatureCNN": [[15, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[16, 0, 1, "", "ParetoArchive"], [16, 3, 1, "", "get_non_dominated"]], "morl_baselines.common.pareto.ParetoArchive": [[16, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[17, 3, 1, "", "expected_utility"], [17, 3, 1, "", "hypervolume"], [17, 3, 1, "", "maximum_utility_loss"], [17, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[13, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[13, 1, 1, "", "add"], [13, 1, 1, "", "get_all_data"], [13, 1, 1, "", "sample"], [13, 1, 1, "", "sample_obs"], [13, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[18, 3, 1, "", "tchebicheff"], [18, 3, 1, "", "weighted_sum"]], "morl_baselines.common.utils": [[14, 3, 1, "", "extrema_weights"], [14, 3, 1, "", "get_grad_norm"], [14, 3, 1, "", "huber"], [14, 3, 1, "", "layer_init"], [14, 3, 1, "", "linearly_decaying_value"], [14, 3, 1, "", "log_episode_info"], [14, 3, 1, "", "make_gif"], [14, 3, 1, "", "polyak_update"], [14, 3, 1, "", "random_weights"]], "morl_baselines.multi_policy.envelope.envelope": [[2, 0, 1, "", "Envelope"]], "morl_baselines.multi_policy.envelope.envelope.Envelope": [[2, 1, 1, "", "act"], [2, 1, 1, "", "ddqn_target"], [2, 1, 1, "", "envelope_target"], [2, 1, 1, "", "eval"], [2, 1, 1, "", "get_config"], [2, 1, 1, "", "load"], [2, 1, 1, "", "max_action"], [2, 1, 1, "", "save"], [2, 1, 1, "", "train"], [2, 1, 1, "", "update"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd": [[3, 0, 1, "", "GPIPD"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD": [[3, 1, 1, "", "eval"], [3, 1, 1, "", "get_config"], [3, 1, 1, "", "gpi_action"], [3, 1, 1, "", "load"], [3, 1, 1, "", "max_action"], [3, 1, 1, "", "save"], [3, 1, 1, "", "set_weight_support"], [3, 1, 1, "", "train"], [3, 1, 1, "", "update"]], "morl_baselines.multi_policy.linear_support.linear_support": [[4, 0, 1, "", "LinearSupport"]], "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport": [[4, 1, 1, "", "add_solution"], [4, 1, 1, "", "compute_corner_weights"], [4, 1, 1, "", "ended"], [4, 1, 1, "", "get_corner_weights"], [4, 1, 1, "", "get_weight_support"], [4, 1, 1, "", "gpi_ls_priority"], [4, 1, 1, "", "is_dominated"], [4, 1, 1, "", "max_scalarized_value"], [4, 1, 1, "", "max_value_lp"], [4, 1, 1, "", "next_weight"], [4, 1, 1, "", "ols_priority"], [4, 1, 1, "", "remove_obsolete_values"], [4, 1, 1, "", "remove_obsolete_weights"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning": [[5, 0, 1, "", "MPMOQLearning"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning": [[5, 1, 1, "", "eval_all_agents"], [5, 1, 1, "", "get_config"], [5, 1, 1, "", "train"]], "morl_baselines.multi_policy.pareto_q_learning.pql": [[6, 0, 1, "", "PQL"]], "morl_baselines.multi_policy.pareto_q_learning.pql.PQL": [[6, 1, 1, "", "calc_non_dominated"], [6, 1, 1, "", "get_config"], [6, 1, 1, "", "get_local_pcs"], [6, 1, 1, "", "get_q_set"], [6, 1, 1, "", "score_hypervolume"], [6, 1, 1, "", "score_pareto_cardinality"], [6, 1, 1, "", "select_action"], [6, 1, 1, "", "track_policy"], [6, 1, 1, "", "train"]], "morl_baselines.multi_policy.pgmorl.pgmorl": [[7, 0, 1, "", "PGMORL"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL": [[7, 1, 1, "", "get_config"], [7, 1, 1, "", "train"]], "morl_baselines.single_policy.esr.eupg": [[10, 0, 1, "", "EUPG"]], "morl_baselines.single_policy.esr.eupg.EUPG": [[10, 1, 1, "", "eval"], [10, 1, 1, "", "get_config"], [10, 1, 1, "", "train"], [10, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_q_learning": [[11, 0, 1, "", "MOQLearning"]], "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning": [[11, 1, 1, "", "eval"], [11, 1, 1, "", "get_config"], [11, 1, 1, "", "train"], [11, 1, 1, "", "update"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "titleterms": {"overview": [0, 20], "multi": [1, 8, 13, 19], "polici": [1, 8, 9], "algorithm": [1, 8, 9, 19], "envelop": 2, "q": [2, 6], "learn": [2, 5, 6, 11, 19], "gpi": 3, "priorit": [3, 13], "dyna": 3, "linear": 4, "support": 4, "mpmoq": 5, "pareto": [6, 16], "pgmorl": 7, "perform": [8, 17], "assess": 8, "introduct": 8, "metric": 8, "storag": 8, "singl": [8, 9], "refer": 8, "eupg": 10, "moq": 11, "commun": 12, "maintain": 12, "contribut": 12, "acknowledg": 12, "replai": 13, "buffer": 13, "object": [13, 19], "divers": 13, "accru": 13, "reward": 13, "miscellan": 14, "neural": 15, "network": 15, "helper": 15, "util": 16, "indic": 17, "scalar": 18, "function": 18, "morl": 19, "baselin": 19, "A": 19, "collect": 19, "reinforc": 19, "featur": 19, "cite": 19}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Overview": [[0, "overview"], [20, "overview"]], "Multi-Policy Algorithms": [[1, "multi-policy-algorithms"]], "Envelope Q-Learning": [[2, "envelope-q-learning"]], "GPI-Prioritized Dyna": [[3, "gpi-prioritized-dyna"]], "Linear Support": [[4, "linear-support"]], "MPMOQ Learning": [[5, "mpmoq-learning"]], "Pareto Q-Learning": [[6, "pareto-q-learning"]], "PGMORL": [[7, "pgmorl"]], "Performance assessments": [[8, "performance-assessments"]], "Introduction": [[8, "introduction"]], "Metrics": [[8, "metrics"]], "Storage": [[8, "storage"]], "Algorithms": [[8, "algorithms"]], "Single-policy algorithms": [[8, "single-policy-algorithms"]], "Multi-policy algorithms": [[8, "multi-policy-algorithms"]], "References": [[8, "references"]], "Single-policy Algorithms": [[9, "single-policy-algorithms"]], "EUPG": [[10, "eupg"]], "MOQ-Learning": [[11, "moq-learning"]], "Community": [[12, "community"]], "Maintainers": [[12, "maintainers"]], "Contributing": [[12, "contributing"]], "Acknowledgements": [[12, "acknowledgements"]], "Replay Buffers": [[13, "replay-buffers"]], "Multi-Objective Replay Buffer": [[13, "multi-objective-replay-buffer"]], "Diverse Replay Buffer": [[13, "diverse-replay-buffer"]], "Prioritized Replay Buffer": [[13, "prioritized-replay-buffer"]], "Accrued Reward Replay Buffer": [[13, "accrued-reward-replay-buffer"]], "Miscellaneous": [[14, "module-morl_baselines.common.utils"]], "Neural Networks helpers": [[15, "module-morl_baselines.common.networks"]], "Pareto utils": [[16, "module-morl_baselines.common.pareto"]], "Performance indicators": [[17, "module-morl_baselines.common.performance_indicators"]], "Scalarization functions": [[18, "module-morl_baselines.common.scalarization"]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[19, "morl-baselines-a-collection-of-multi-objective-reinforcement-learning-algorithms"]], "Features of MORL-Baselines": [[19, "features-of-morl-baselines"]], "Citing MORL-Baselines": [[19, "citing-morl-baselines"]]}, "indexentries": {"envelope (class in morl_baselines.multi_policy.envelope.envelope)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope"]], "act() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.act"]], "ddqn_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.ddqn_target"]], "envelope_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.envelope_target"]], "eval() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.eval"]], "get_config() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.get_config"]], "load() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.load"]], "max_action() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.max_action"]], "save() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.save"]], "train() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.train"]], "update() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.update"]], "gpipd (class in morl_baselines.multi_policy.gpi_pd.gpi_pd)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD"]], "eval() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.eval"]], "get_config() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.get_config"]], "gpi_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.gpi_action"]], "load() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.load"]], "max_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.max_action"]], "save() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.save"]], "set_weight_support() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.set_weight_support"]], "train() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train"]], "update() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.update"]], "linearsupport (class in morl_baselines.multi_policy.linear_support.linear_support)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport"]], "add_solution() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.add_solution"]], "compute_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.compute_corner_weights"]], "ended() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ended"]], "get_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_corner_weights"]], "get_weight_support() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_weight_support"]], "gpi_ls_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.gpi_ls_priority"]], "is_dominated() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.is_dominated"]], "max_scalarized_value() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_scalarized_value"]], "max_value_lp() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_value_lp"]], "next_weight() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.next_weight"]], "ols_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ols_priority"]], "remove_obsolete_values() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_values"]], "remove_obsolete_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_weights"]], "mpmoqlearning (class in morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning"]], "eval_all_agents() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.eval_all_agents"]], "get_config() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.get_config"]], "train() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.train"]], "pql (class in morl_baselines.multi_policy.pareto_q_learning.pql)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL"]], "calc_non_dominated() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.calc_non_dominated"]], "get_config() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_config"]], "get_local_pcs() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_local_pcs"]], "get_q_set() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_q_set"]], "score_hypervolume() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_hypervolume"]], "score_pareto_cardinality() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_pareto_cardinality"]], "select_action() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.select_action"]], "track_policy() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.track_policy"]], "train() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.train"]], "pgmorl (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[7, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL"]], "get_config() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[7, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.get_config"]], "train() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[7, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.train"]], "eupg (class in morl_baselines.single_policy.esr.eupg)": [[10, "morl_baselines.single_policy.esr.eupg.EUPG"]], "eval() (morl_baselines.single_policy.esr.eupg.eupg method)": [[10, "morl_baselines.single_policy.esr.eupg.EUPG.eval"]], "get_config() (morl_baselines.single_policy.esr.eupg.eupg method)": [[10, "morl_baselines.single_policy.esr.eupg.EUPG.get_config"]], "train() (morl_baselines.single_policy.esr.eupg.eupg method)": [[10, "morl_baselines.single_policy.esr.eupg.EUPG.train"]], "update() (morl_baselines.single_policy.esr.eupg.eupg method)": [[10, "morl_baselines.single_policy.esr.eupg.EUPG.update"]], "moqlearning (class in morl_baselines.single_policy.ser.mo_q_learning)": [[11, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning"]], "eval() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[11, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.eval"]], "get_config() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[11, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.get_config"]], "train() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[11, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.train"]], "update() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[11, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.update"]], "accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[13, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer"]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory"]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer"]], "replaybuffer (class in morl_baselines.common.buffer)": [[13, "morl_baselines.common.buffer.ReplayBuffer"]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[13, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add"]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[13, "morl_baselines.common.buffer.ReplayBuffer.add"]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.add"]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add"]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample"]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree"]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[13, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup"]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe"]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace"]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.get"]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[13, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[13, "morl_baselines.common.buffer.ReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data"]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data"]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error"]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write"]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value"]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full"]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec"]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace"]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[13, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample"]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[13, "morl_baselines.common.buffer.ReplayBuffer.sample"]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.sample"]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample"]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[13, "morl_baselines.common.buffer.ReplayBuffer.sample_obs"]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs"]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances"]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[13, "morl_baselines.common.diverse_buffer.DiverseMemory.update"]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[13, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities"]], "extrema_weights() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.extrema_weights"]], "get_grad_norm() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.get_grad_norm"]], "huber() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.huber"]], "layer_init() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.layer_init"]], "linearly_decaying_value() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.linearly_decaying_value"]], "log_episode_info() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.log_episode_info"]], "make_gif() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.make_gif"]], "module": [[14, "module-morl_baselines.common.utils"], [15, "module-morl_baselines.common.networks"], [16, "module-morl_baselines.common.pareto"], [17, "module-morl_baselines.common.performance_indicators"], [18, "module-morl_baselines.common.scalarization"]], "morl_baselines.common.utils": [[14, "module-morl_baselines.common.utils"]], "polyak_update() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.polyak_update"]], "random_weights() (in module morl_baselines.common.utils)": [[14, "morl_baselines.common.utils.random_weights"]], "naturecnn (class in morl_baselines.common.networks)": [[15, "morl_baselines.common.networks.NatureCNN"]], "forward() (morl_baselines.common.networks.naturecnn method)": [[15, "morl_baselines.common.networks.NatureCNN.forward"]], "mlp() (in module morl_baselines.common.networks)": [[15, "morl_baselines.common.networks.mlp"]], "morl_baselines.common.networks": [[15, "module-morl_baselines.common.networks"]], "paretoarchive (class in morl_baselines.common.pareto)": [[16, "morl_baselines.common.pareto.ParetoArchive"]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[16, "morl_baselines.common.pareto.ParetoArchive.add"]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[16, "morl_baselines.common.pareto.get_non_dominated"]], "morl_baselines.common.pareto": [[16, "module-morl_baselines.common.pareto"]], "expected_utility() (in module morl_baselines.common.performance_indicators)": [[17, "morl_baselines.common.performance_indicators.expected_utility"]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[17, "morl_baselines.common.performance_indicators.hypervolume"]], "maximum_utility_loss() (in module morl_baselines.common.performance_indicators)": [[17, "morl_baselines.common.performance_indicators.maximum_utility_loss"]], "morl_baselines.common.performance_indicators": [[17, "module-morl_baselines.common.performance_indicators"]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[17, "morl_baselines.common.performance_indicators.sparsity"]], "morl_baselines.common.scalarization": [[18, "module-morl_baselines.common.scalarization"]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[18, "morl_baselines.common.scalarization.tchebicheff"]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[18, "morl_baselines.common.scalarization.weighted_sum"]]}})