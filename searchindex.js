Search.setIndex({"docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/envelope", "algos/multi_policy/gpi_pd", "algos/multi_policy/linear_support", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pcn", "algos/multi_policy/pgmorl", "algos/performances", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "index", "quickstart/overview"], "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/envelope.md", "algos/multi_policy/gpi_pd.md", "algos/multi_policy/linear_support.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pcn.md", "algos/multi_policy/pgmorl.md", "algos/performances.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "index.md", "quickstart/overview.md"], "titles": ["Overview", "Multi-Policy Algorithms", "Envelope Q-Learning", "GPI-Prioritized Dyna", "Linear Support", "MPMOQ Learning", "Pareto Q-Learning", "Pareto Conditioned Networks", "PGMORL", "Performance assessments", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "terms": {"morl": [0, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 15, 18, 21], "baselin": [0, 2, 3, 5, 6, 7, 8, 11, 12, 13, 15, 21], "contain": [0, 14, 15, 20, 21], "multipl": [0, 2, 14], "implement": [0, 4, 5, 9, 13, 14, 20, 21], "multi": [0, 2, 3, 5, 6, 8, 11, 12, 16, 18, 21], "object": [0, 2, 3, 4, 5, 6, 8, 9, 11, 12, 18], "reinforc": [0, 2, 5, 6, 8, 9, 11, 12, 14, 16], "learn": [0, 3, 8, 9, 11, 13, 14, 16], "algorithm": [0, 2, 3, 4, 5, 8, 11, 12, 13, 14, 18, 21], "The": [0, 2, 5, 6, 9, 11, 14, 15, 16, 17, 21], "follow": [0, 9, 14, 15, 16, 20, 21], "tabl": [0, 12], "list": [0, 2, 3, 4, 5, 8, 11, 14, 15, 16, 18], "ar": [0, 4, 9, 13, 14, 15, 17, 18, 20], "current": [0, 2, 4, 6, 13, 14, 15, 16, 18], "name": [0, 6], "singl": [0, 12, 20, 21], "polici": [0, 2, 3, 4, 5, 6, 7, 11, 12, 18, 20, 21], "esr": [0, 11, 14, 20, 21], "ser": [0, 12, 20, 21], "observ": [0, 2, 7, 11, 12, 14, 16], "space": [0, 15], "action": [0, 2, 3, 5, 6, 7, 11, 12, 14], "paper": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 16, 18, 20], "gpi": [0, 4, 5, 9], "l": [0, 3, 4, 9, 18], "pd": [0, 3, 9], "continu": [0, 8, 9], "discret": [0, 9], "supplementari": [0, 8], "materi": [0, 8], "envelop": [0, 9], "q": [0, 5, 9, 12, 13], "pgmorl": [0, 9, 18], "1": [0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15], "pareto": [0, 9, 13, 18, 20], "condit": [0, 2, 11], "network": [0, 2, 3, 11, 15], "pcn": [0, 7, 9], "2": [0, 3, 8, 9, 14], "mo": [0, 5, 8, 9, 12, 20, 21], "mpmoqlearn": [0, 5, 9], "outer": [0, 5], "loop": [0, 5], "moql": 0, "optimist": [0, 4], "linear": [0, 5], "support": [0, 3, 5, 9], "ol": [0, 4, 9], "section": [0, 4], "3": [0, 4, 9], "thesi": [0, 4], "expect": [0, 5, 9, 11, 18], "util": [0, 4, 5, 9, 11, 12, 15, 16, 18, 20], "gradient": [0, 11], "eupg": [0, 9, 13], "warn": [0, 9], "have": [0, 9, 13, 15, 17, 20], "been": [0, 15, 17, 20], "benchmark": 0, "yet": 0, "some": [0, 9, 18], "them": [0, 9, 13], "limit": 0, "featur": [0, 13, 16], "i": [0, 2, 4, 5, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21], "environ": [0, 2, 3, 4, 5, 7, 9, 11, 12, 20, 21], "assum": 0, "determinist": 0, "transit": [0, 14], "class": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 16, 17], "morl_baselin": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20], "multi_polici": [2, 3, 4, 5, 6, 7, 8, 21], "env": [2, 3, 4, 5, 6, 7, 8, 11, 12, 15], "learning_r": [2, 3, 5, 7, 8, 11, 12], "float": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 16, 18, 19], "0": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 16], "0003": [2, 3, 8], "initial_epsilon": [2, 3, 5, 6, 12], "01": [2, 3, 7, 14, 15], "final_epsilon": [2, 3, 5, 6, 12], "epsilon_decay_step": [2, 3, 5, 12], "int": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 16, 18, 19], "none": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15], "tau": [2, 3, 15, 19], "target_net_update_freq": [2, 3], "1000": [2, 3, 5, 11, 12], "buffer_s": [2, 3, 11], "1000000": [2, 3], "net_arch": [2, 3, 8, 11, 16], "256": [2, 3], "batch_siz": [2, 3, 7, 14], "learning_start": [2, 3, 12], "100": [2, 3, 6, 7, 8], "gradient_upd": [2, 3], "gamma": [2, 3, 5, 6, 7, 8, 11, 12], "99": [2, 3, 6, 11], "max_grad_norm": [2, 3, 8], "bool": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14, 15, 16, 18], "true": [2, 3, 4, 5, 6, 8, 9, 11, 12, 14, 15, 18], "num_sample_w": 2, "4": [2, 8], "per": [2, 3, 5, 6, 12, 16], "per_alpha": 2, "6": [2, 3, 8], "initial_homotopy_lambda": 2, "final_homotopy_lambda": 2, "homotopy_decay_step": 2, "project_nam": [2, 3, 5, 6, 7, 8, 11, 12], "str": [2, 3, 4, 5, 6, 7, 8, 11, 12, 15, 18], "experiment_nam": [2, 3, 5, 6, 7, 8, 11, 12], "log": [2, 3, 5, 6, 7, 8, 11, 12, 15], "devic": [2, 3, 7, 8, 11, 14], "auto": [2, 3, 7, 8, 11], "lean": 2, "us": [2, 3, 4, 5, 6, 9, 11, 12, 14, 15, 16, 18, 21], "emb": 2, "take": 2, "weight": [2, 3, 4, 5, 7, 9, 11, 12, 15, 18, 19, 20], "input": [2, 15, 16, 17], "main": [2, 13, 14], "chang": [2, 3, 17], "thi": [2, 5, 7, 9, 13, 14, 15, 16, 17, 19, 20, 21], "compar": [2, 9], "scalar": [2, 4, 5, 9, 11, 12, 15], "cn": 2, "dqn": [2, 15, 16], "target": [2, 14, 15], "updat": [2, 3, 5, 7, 11, 12, 14, 15], "r": [2, 18], "yang": 2, "x": [2, 15], "sun": 2, "k": [2, 5, 6, 12], "narasimhan": 2, "A": [2, 5, 6, 7, 9, 11, 12, 14, 15, 18], "gener": [2, 3, 4, 5, 8, 9, 11, 12, 15], "adapt": [2, 19], "arxiv": [2, 3, 4], "1908": 2, "08342": 2, "c": [2, 3, 9], "nov": [2, 8, 9], "2019": 2, "access": 2, "sep": 2, "06": 2, "2021": 2, "onlin": 2, "avail": [2, 7, 8, 9, 14, 20], "http": [2, 3, 4, 7, 8, 9, 14, 15, 17, 20], "org": [2, 3, 4, 7, 15], "ab": [2, 3, 4], "act": 2, "ob": [2, 3, 4, 5, 7, 11, 12, 14], "tensor": [2, 3, 14, 15, 16], "w": [2, 3, 4, 5, 7, 8, 9, 11, 12], "epsilon": [2, 4, 5, 15], "greedili": [2, 12], "select": [2, 3, 6], "an": [2, 3, 4, 6, 9, 13, 15, 16], "given": [2, 3, 5, 6, 7, 11, 12, 14, 15], "paramet": [2, 3, 4, 5, 6, 8, 11, 12, 14, 15, 16, 17, 18, 19, 20], "vector": [2, 3, 4, 5, 6, 15, 16, 17, 18, 19], "return": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 17, 18, 19, 20], "integ": 2, "repres": [2, 16], "ddqn_target": 2, "doubl": 2, "envelope_target": 2, "sampled_w": 2, "comput": [2, 3, 4, 6, 9, 14, 15, 18], "set": [2, 3, 4, 5, 6, 7, 14, 17, 18, 21], "sampl": [2, 3, 14, 15], "eval": [2, 3, 5, 7, 11, 12], "ndarrai": [2, 3, 4, 5, 6, 7, 8, 11, 12, 15, 16, 17, 18, 19], "give": [2, 11, 14], "best": [2, 11, 12, 19], "np": [2, 3, 4, 11, 18], "arrai": [2, 5, 7, 8, 11, 12, 14, 17, 20], "option": [2, 3, 4, 6, 11], "get_config": [2, 3, 5, 6, 7, 8, 11, 12], "dictionari": [2, 5, 6, 8, 11, 12, 14, 15], "configur": [2, 3, 5, 6, 7, 8, 11, 12], "dict": [2, 5, 6, 7, 8, 11, 12, 15], "config": [2, 5, 8, 11, 12], "load": [2, 3], "path": [2, 3], "load_replay_buff": [2, 3], "model": [2, 3, 7], "replai": [2, 3, 21], "buffer": [2, 3, 11, 20, 21], "specifi": [2, 14], "whether": [2, 3, 12, 14, 15, 16], "too": 2, "max_act": [2, 3], "highest": [2, 4], "valu": [2, 4, 5, 6, 9, 12, 14, 15, 18, 19], "save": [2, 3, 7, 15], "save_replay_buff": [2, 3], "save_dir": [2, 3], "filenam": [2, 3, 7], "directori": 2, "train": [2, 3, 5, 6, 7, 8, 11, 12, 15], "total_timestep": [2, 3, 11, 12], "total_episod": 2, "reset_num_timestep": [2, 3, 12], "eval_env": [2, 3, 5, 11, 12], "eval_freq": [2, 3, 5, 11, 12], "reset_learning_start": [2, 3], "fals": [2, 3, 4, 5, 7, 8, 12, 14, 16], "agent": [2, 3, 4, 7, 8, 9, 11, 12, 15], "total": 2, "number": [2, 3, 4, 5, 6, 11, 12, 14, 15, 16], "timestep": [2, 3, 5, 11, 12, 15], "If": [2, 4, 5, 13, 14], "randomli": 2, "everi": [2, 6], "episod": [2, 3, 5, 6, 11, 15], "done": [2, 14], "ignor": 2, "reset": [2, 3, 12], "when": [2, 4, 12, 14], "time": [2, 4, 12], "evalu": [2, 3, 4, 5, 6, 7, 11, 12, 17], "frequenc": [2, 5, 11], "start": [2, 3, 12, 14], "": [2, 8, 9, 11, 14, 15, 20, 21], "e": [2, 5, 7, 11, 14, 18, 20], "g": [2, 5, 11, 18, 20], "experi": [2, 11, 14, 20], "from": [2, 4, 6, 7, 9, 11, 13, 14, 15, 16, 18, 20], "gpi_pd": 3, "gpipd": 3, "type": [3, 16, 18], "num_net": 3, "use_gpi": [3, 5], "alpha_p": 3, "min_prior": [3, 14, 15], "drop_rat": [3, 16], "layer_norm": [3, 16], "dynamics_normalize_input": 3, "dynamics_uncertainty_threshold": 3, "5": [3, 5, 8, 12], "dynamics_train_freq": 3, "callabl": [3, 6, 18, 19], "function": [3, 4, 5, 6, 9, 12, 14, 15, 16, 17, 18, 20], "lambda": [3, 14], "dynamics_rollout_len": 3, "dynamics_rollout_start": 3, "5000": 3, "dynamics_rollout_freq": 3, "250": [3, 7], "dynamics_rollout_batch_s": 3, "10000": 3, "dynamics_buffer_s": 3, "400000": 3, "dynamics_net_arch": 3, "200": 3, "dynamics_ensemble_s": 3, "dynamics_num_elit": 3, "real_ratio": 3, "05": [3, 14], "torch": [3, 12, 15, 16], "effici": 3, "via": 3, "improv": [3, 4], "luca": [3, 13, 20], "n": [3, 7, 13, 14, 15, 20], "alegr": [3, 13, 20], "ana": 3, "bazzan": 3, "diederik": 3, "m": [3, 5, 7, 9, 12, 18], "roijer": [3, 4, 9, 11, 18], "ann": 3, "now\u00e9": [3, 6, 7], "bruno": 3, "da": 3, "silva": 3, "aama": 3, "2023": 3, "2301": [3, 4], "07784": [3, 4], "gpi_act": 3, "return_policy_index": 3, "include_w": 3, "greedi": [3, 12], "set_weight_support": 3, "weight_list": 3, "timesteps_per_it": 3, "max_it": 3, "15": [3, 6], "weight_selection_algo": [3, 5], "ref_front": 3, "gym": 3, "iter": [3, 5, 15], "refer": [3, 5, 8, 18, 19], "front": [3, 6, 9, 17, 18], "maximum": [3, 4, 9, 14, 18], "utiltii": 3, "loss": [3, 9, 15, 18], "train_iter": 3, "weight_support": 3, "change_w_every_episod": 3, "one": [3, 12, 15, 18], "end": [3, 4, 14], "each": [3, 9, 12, 14, 16, 18, 19], "between": [3, 9, 12, 18], "linear_support": 4, "linearsupport": 4, "num_object": 4, "verbos": [4, 15], "corner": 4, "both": [4, 9, 20], "info": [4, 15], "pub": 4, "pdf": [4, 7, 8], "add_solut": 4, "add": [4, 14, 17], "new": [4, 13, 14], "optim": [4, 6, 9, 20], "indic": [4, 5, 14, 17], "remov": [4, 14, 17], "cc": [4, 9], "being": 4, "domin": [4, 6, 17, 19], "compute_corner_weight": 4, "see": [4, 21], "definit": [4, 20], "19": 4, "typo": 4, "sign": 4, "should": [4, 14], "queue": 4, "empti": 4, "get_corner_weight": 4, "top_k": 4, "get_weight_support": 4, "gpi_ls_prior": 4, "gpi_expanded_set": 4, "get": [4, 6, 7, 13, 14], "prioriti": [4, 14, 15], "is_domin": 4, "check": [4, 14], "ani": [4, 18], "otherwis": [4, 5], "max_scalarized_valu": 4, "max_value_lp": 4, "w_new": 4, "upper": 4, "bound": 4, "next_weight": 4, "algo": 4, "gpi_ag": 4, "mopolici": 4, "rep_ev": 4, "next": [4, 14], "either": [4, 15], "ols_prior": 4, "remove_obsolete_valu": 4, "which": [4, 9, 14, 15, 16, 17, 20], "all": [4, 9, 13, 14, 17, 20, 21], "visit": 4, "remove_obsolete_weight": 4, "new_valu": 4, "better": 4, "than": 4, "previou": [4, 14], "multi_policy_moqlearn": 5, "mp_mo_q_learn": 5, "weighted_sum": [5, 12, 19], "9": [5, 12], "random": [5, 15], "epsilon_ol": 5, "use_gpi_polici": 5, "transfer_q_t": 5, "dyna": [5, 12], "dyna_upd": [5, 12], "multipolici": 5, "moq": [5, 9], "version": [5, 9], "mo_q_learn": [5, 12], "van": [5, 6, 12], "moffaert": [5, 6, 12], "drugan": [5, 12], "now": [5, 11, 12], "novel": [5, 12], "design": [5, 12], "techniqu": [5, 12], "2013": [5, 12], "doi": [5, 9, 12], "10": [5, 7, 8, 9, 12], "1109": [5, 12], "adprl": [5, 12], "6615007": [5, 12], "delete_polici": 5, "delete_indx": 5, "delet": 5, "index": [5, 14], "num_iter": 5, "timesteps_per_iter": 5, "ref_point": [5, 6, 7, 8, 18], "test_weight": 5, "num_episodes_ev": 5, "point": [5, 9, 17, 18, 19], "hypervolum": [5, 6, 9, 18], "calcul": [5, 17], "epsilon_linear_support": 5, "doe": 5, "method": [5, 6, 9, 12, 14, 15], "pareto_q_learn": 6, "pql": 6, "8": 6, "epsilon_decai": 6, "seed": [6, 8, 9, 15], "tabular": 6, "reli": [6, 9, 12, 18, 19], "prune": [6, 20], "journal": [6, 20], "machin": [6, 8, 9], "research": 6, "vol": [6, 9], "pp": [6, 7, 8, 9], "3483": 6, "3512": 6, "2014": 6, "calc_non_domin": 6, "state": 6, "non": [6, 17], "get_local_pc": 6, "collect": [6, 16], "local": 6, "pc": 6, "default": [6, 14, 15, 18], "get_q_set": 6, "pair": [6, 14], "score_hypervolum": 6, "score": 6, "base": [6, 9, 11, 18], "upon": 6, "metric": [6, 18], "score_pareto_cardin": 6, "cardin": 6, "select_act": 6, "score_func": 6, "track_polici": 6, "vec": 6, "track": 6, "its": [6, 14], "array_lik": 6, "num_episod": 6, "3000": 6, "log_everi": 6, "action_ev": 6, "result": 6, "final": [6, 15], "scaling_factor": 7, "32": [7, 8], "hidden_dim": 7, "64": [7, 8], "reymond": 7, "bargiacchi": 7, "2022": [7, 9, 20], "mai": 7, "In": [7, 9], "proceed": [7, 8, 9], "21st": 7, "intern": [7, 8, 9], "confer": [7, 8, 9], "autonom": [7, 9], "multiag": 7, "system": [7, 9], "1110": 7, "1118": 7, "www": 7, "ifaama": 7, "aamas2022": 7, "p1110": 7, "credit": 7, "code": [7, 14, 17, 20], "refactor": 7, "author": [7, 20], "github": [7, 14, 20], "com": [7, 14, 17, 20], "mathieu": 7, "max_return": 7, "pcn_model": 7, "savedir": 7, "set_desired_return_and_horizon": 7, "desired_return": 7, "desired_horizon": 7, "desir": 7, "horizon": 7, "num_er_episod": 7, "500": 7, "total_time_step": 7, "10000000": 7, "num_step_episod": 7, "num_model_upd": 7, "max_buffer_s": 7, "env_id": 8, "halfcheetah": 8, "v4": 8, "num_env": 8, "pop_siz": 8, "warmup_iter": 8, "80": 8, "steps_per_iter": 8, "2048": 8, "limit_env_step": 8, "5000000": 8, "evolutionary_iter": 8, "20": 8, "num_weight_candid": 8, "7": 8, "num_performance_buff": 8, "performance_buffer_s": 8, "min_weight": 8, "max_weight": 8, "delta_weight": 8, "995": 8, "torch_determinist": 8, "num_minibatch": 8, "update_epoch": 8, "anneal_lr": 8, "clip_coef": 8, "ent_coef": 8, "vf_coef": 8, "clip_vloss": 8, "norm_adv": 8, "target_kl": 8, "gae": 8, "gae_lambda": 8, "95": 8, "predict": [8, 9, 16], "guid": [8, 9, 20], "j": [8, 9], "xu": [8, 9], "y": [8, 9], "tian": [8, 9], "p": [8, 9, 18], "ma": [8, 9], "d": [8, 9, 11, 18], "ru": [8, 9], "sueda": [8, 9], "matusik": [8, 9], "robot": [8, 9], "control": [8, 9, 16], "37th": [8, 9], "2020": [8, 9], "10607": [8, 9], "10616": [8, 9], "mlr": [8, 9], "press": [8, 9], "v119": [8, 9], "xu20h": [8, 9], "html": [8, 9, 15], "peopl": [8, 13], "csail": 8, "mit": 8, "edu": 8, "jiex": 8, "supp": 8, "document": [9, 20, 21], "work": 9, "progress": 9, "To": 9, "ensur": 9, "correct": 9, "we": [9, 13, 14, 18, 20], "want": [9, 13], "test": [9, 20], "variou": [9, 13, 18], "For": [9, 20], "sake": 9, "reproduc": 9, "run": [9, 11], "mainten": 9, "purpos": 9, "long": 9, "term": 9, "conduct": 9, "gymnasium": [9, 20, 21], "henc": 9, "abl": 9, "were": 9, "present": 9, "origin": [9, 13, 20], "propos": 9, "qualiti": [9, 18], "pf": [9, 18], "converg": 9, "divers": 9, "hybrid": 9, "common": [9, 14, 15, 16, 17, 18, 19, 21], "performance_ind": [9, 18], "sparsiti": [9, 18], "averag": [9, 15, 18], "distanc": [9, 14, 18], "consecut": 9, "igd": [9, 18], "sota": 9, "moo": [9, 18], "literatur": 9, "It": [9, 15, 16, 19, 20], "requir": [9, 19], "can": [9, 13], "posteriori": 9, "That": [9, 15], "do": 9, "merg": 9, "found": 9, "respect": 9, "moreov": 9, "assumpt": 9, "user": 9, "These": [9, 14], "allow": 9, "idea": [9, 11, 13], "wherea": 9, "other": [9, 12, 14, 20], "eum": [9, 18], "mul": [9, 18], "problem": 9, "know": [9, 14], "report": [9, 20], "wandb": [9, 15], "easi": 9, "manipul": 9, "export": 9, "data": [9, 14], "below": [9, 14], "along": 9, "dst": 9, "mountaincar": 9, "fishwood": 9, "fruit": 9, "tree": [9, 14], "mario": 9, "half": 9, "cheetah": 9, "obj": 9, "hopper": 9, "note": 9, "tweak": 9, "posit": [9, 14], "reward": [9, 11, 19, 20], "onli": [9, 18, 20], "feel": 9, "modif": 9, "good": 9, "practic": [9, 20], "offici": 9, "instead": 9, "our": [9, 13], "cannot": 9, "minecart": 9, "full": [9, 14], "hay": [9, 13], "et": [9, 15, 16], "al": [9, 15, 16], "plan": [9, 20], "36": 9, "apr": 9, "1007": 9, "s10458": 9, "022": 9, "09552": 9, "zintgraf": [9, 18], "t": [9, 18], "v": [9, 18], "kanter": [9, 18], "f": [9, 13, 18], "oliehoek": [9, 18], "beau": [9, 18], "approach": [9, 18], "2015": [9, 15, 16, 18], "single_polici": [11, 12, 21], "100000": [11, 14], "50": [11, 15], "001": 11, "accru": 11, "futur": 11, "steckelmach": [11, 13], "2018": 11, "accrued_reward": [11, 14], "moqlearn": 12, "id": [12, 14, 15], "numpi": [12, 14, 18, 19, 20], "parent_writ": 12, "tensorboard": 12, "writer": [12, 15], "summarywrit": [12, 15], "maintain": 12, "choos": 12, "move": [12, 14], "scalarized_q_valu": 12, "start_tim": 12, "500000": 12, "max": 12, "recal": 12, "launch": 12, "discord": 13, "server": 13, "where": 13, "you": 13, "ask": 13, "question": [13, 17], "help": 13, "repositori": [13, 20], "join": 13, "here": 13, "florian": [13, 20], "felten": [13, 20], "ffelten": 13, "lucasalegr": [13, 20], "open": 13, "alwai": [13, 19], "happi": 13, "receiv": 13, "bug": 13, "fix": 13, "discuss": 13, "your": 13, "u": 13, "also": 13, "issu": 13, "pull": 13, "request": 13, "directli": 13, "asid": 13, "contributor": 13, "mani": 13, "who": 13, "project": 13, "wai": [13, 14], "would": 13, "like": 13, "thank": 13, "willem": 13, "r\u00f6pke": 13, "hi": 13, "wilrop": 13, "deni": 13, "conor": 13, "provid": [13, 14, 17, 20], "librari": [14, 20], "replaybuff": 14, "obs_shap": 14, "action_dim": 14, "rew_dim": 14, "max_siz": 14, "obs_dtyp": 14, "float32": 14, "action_dtyp": 14, "next_ob": 14, "get_all_data": 14, "max_sampl": 14, "tupl": 14, "replac": 14, "use_c": 14, "to_tensor": 14, "batch": 14, "size": [14, 15], "cer": 14, "convert": 14, "pytorch": [14, 20], "sample_ob": 14, "diverse_buff": 14, "diversememori": 14, "main_capac": 14, "sec_capac": 14, "trace_divers": 14, "crowding_divers": 14, "value_funct": 14, "integr": 14, "secondari": 14, "extract": 14, "axelabel": 14, "dynmorl": 14, "error": 14, "trace_id": 14, "pred_idx": 14, "tree_id": 14, "proport": 14, "same": 14, "treat": 14, "trace": 14, "determin": 14, "store": 14, "identifi": 14, "relev": 14, "node": 14, "wa": 14, "add_sampl": 14, "write": 14, "add_tre": 14, "dupe": 14, "trg_i": 14, "src_i": 14, "copi": 14, "sourc": [14, 17], "extract_trac": 14, "those": 14, "get_data": 14, "include_indic": 14, "includ": 14, "get_error": 14, "idx": 14, "correspond": 14, "get_sec_writ": 14, "secondary_trac": 14, "reserved_idx": 14, "find": 14, "free": 14, "spot": 14, "memori": [14, 17], "recurs": 14, "past": 14, "low": 14, "crowd": 14, "get_trace_valu": 14, "trace_tupl": 14, "appli": 14, "main_mem_is_ful": 14, "becaus": 14, "circular": 14, "fill": [14, 15], "suffici": 14, "move_to_sec": 14, "span": 14, "remove_trac": 14, "whose": 14, "sec_dist": 14, "prioritized_buff": 14, "prioritizedreplaybuff": 14, "1e": 14, "update_prior": 14, "accrued_reward_buff": 14, "accruedrewardreplaybuff": 14, "action_shap": 14, "cleanup": 14, "whole": 14, "order": 14, "element": [14, 15, 17], "equally_spaced_weight": 15, "dim": 15, "equal": 15, "simplex": 15, "riesz": 15, "energi": 15, "pymoo": [15, 18], "misc": [15, 20], "reference_direct": 15, "extrema_weight": 15, "extrema": 15, "rest": 15, "get_grad_norm": 15, "param": 15, "how": 15, "grad": 15, "norm": 15, "insid": 15, "nn": [15, 16], "clip_grad_norm_": 15, "huber": 15, "minimum": 15, "layer_init": 15, "layer": [15, 16], "orthogon": 15, "weight_gain": 15, "bias_const": 15, "initi": 15, "gain": 15, "constant": 15, "bia": 15, "linearly_decaying_valu": 15, "initial_valu": 15, "decay_period": 15, "step": 15, "warmup_step": 15, "final_valu": 15, "linearli": 15, "decai": 15, "natur": [15, 16], "schedul": 15, "mnih": [15, 16], "begin": 15, "until": 15, "taken": 15, "period": 15, "over": 15, "complet": 15, "so": [15, 19], "far": [15, 19], "befor": 15, "accord": 15, "log_episode_info": 15, "global_timestep": 15, "inform": 15, "last": 15, "automat": [15, 19, 20], "recordstatisticswrapp": 15, "statist": 15, "global": 15, "print": 15, "make_gif": 15, "fullpath": 15, "fp": 15, "length": [15, 16], "300": 15, "render": 15, "gif": 15, "polyak_upd": 15, "target_param": 15, "polyak": 15, "coeffici": 15, "usual": 15, "small": 15, "random_weight": 15, "dist": 15, "dirichlet": 15, "normal": [15, 16], "gaussian": 15, "distribut": 15, "alpha": 15, "equival": 15, "uniformli": 15, "naturecnn": 16, "observation_shap": 16, "features_dim": 16, "512": 16, "cnn": 16, "volodymyr": 16, "human": 16, "level": 16, "through": 16, "deep": 16, "518": 16, "7540": 16, "529": 16, "533": 16, "forward": 16, "mlp": 16, "input_dim": 16, "output_dim": 16, "activation_fn": 16, "modul": 16, "activ": 16, "relu": 16, "sequenti": 16, "creat": 16, "perceptron": 16, "fulli": 16, "connect": 16, "dimens": [16, 19], "output": 16, "architectur": 16, "net": [16, 21], "unit": 16, "after": 16, "dropout": 16, "rate": 16, "paretoarch": 17, "archiv": 17, "candid": 17, "ineffici": 17, "get_non_domin": 17, "subset": 17, "stackoverflow": 17, "32791911": 17, "fast": 17, "python": 17, "answer": 17, "wrong": 17, "import": 17, "made": [17, 18], "get_non_dominated_ind": 17, "solut": 17, "boolean": 17, "rl": 18, "mostli": 18, "axiomat": 18, "hv": 18, "customli": 18, "expected_util": 18, "weights_set": 18, "dot": [18, 19], "similar": 18, "But": 18, "need": 18, "approxim": 18, "assess": 18, "product": [18, 19], "_supportsarrai": 18, "dtype": 18, "_nestedsequ": 18, "complex": 18, "byte": 18, "maximum_utility_loss": 18, "reference_set": 18, "basic": 18, "tchebicheff": 19, "reward_dim": 19, "seen": 19, "compon": 19, "sure": 19, "sum": 19, "aim": 20, "reliabl": 20, "strictli": 20, "api": 20, "differ": 20, "standard": 20, "detail": [20, 21], "mdp": 20, "momdp": 20, "suggest": 20, "read": 20, "under": 20, "criteria": 20, "perform": 20, "bias": 20, "dashboard": 20, "lint": 20, "format": 20, "enforc": 20, "pre": 20, "commit": 20, "hook": 20, "well": 20, "etc": [20, 21], "against": 20, "ones": 20, "hyper": 20, "titl": 20, "year": 20, "publish": 20, "howpublish": 20, "url": 20, "As": 21, "much": 21, "possibl": 21, "repo": 21, "tri": 21, "file": 21, "rule": 21, "structur": 21, "exampl": 21, "recur": 21, "concept": 21, "neural": 21, "more": 21}, "objects": {"morl_baselines.common.accrued_reward_buffer": [[14, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[14, 1, 1, "", "add"], [14, 1, 1, "", "cleanup"], [14, 1, 1, "", "get_all_data"], [14, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[14, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[14, 1, 1, "", "add"], [14, 1, 1, "", "get_all_data"], [14, 1, 1, "", "sample"], [14, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[14, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[14, 1, 1, "", "add"], [14, 1, 1, "", "add_sample"], [14, 1, 1, "", "add_tree"], [14, 1, 1, "", "dupe"], [14, 1, 1, "", "extract_trace"], [14, 1, 1, "", "get"], [14, 1, 1, "", "get_data"], [14, 1, 1, "", "get_error"], [14, 1, 1, "", "get_sec_write"], [14, 1, 1, "", "get_trace_value"], [14, 1, 1, "", "main_mem_is_full"], [14, 1, 1, "", "move_to_sec"], [14, 1, 1, "", "remove_trace"], [14, 1, 1, "", "sample"], [14, 1, 1, "", "sec_distances"], [14, 1, 1, "", "update"]], "morl_baselines.common": [[16, 2, 0, "-", "networks"], [17, 2, 0, "-", "pareto"], [18, 2, 0, "-", "performance_indicators"], [19, 2, 0, "-", "scalarization"], [15, 2, 0, "-", "utils"]], "morl_baselines.common.networks": [[16, 0, 1, "", "NatureCNN"], [16, 3, 1, "", "mlp"]], "morl_baselines.common.networks.NatureCNN": [[16, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[17, 0, 1, "", "ParetoArchive"], [17, 3, 1, "", "get_non_dominated"], [17, 3, 1, "", "get_non_dominated_inds"]], "morl_baselines.common.pareto.ParetoArchive": [[17, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[18, 3, 1, "", "expected_utility"], [18, 3, 1, "", "hypervolume"], [18, 3, 1, "", "maximum_utility_loss"], [18, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[14, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[14, 1, 1, "", "add"], [14, 1, 1, "", "get_all_data"], [14, 1, 1, "", "sample"], [14, 1, 1, "", "sample_obs"], [14, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[19, 3, 1, "", "tchebicheff"], [19, 3, 1, "", "weighted_sum"]], "morl_baselines.common.utils": [[15, 3, 1, "", "equally_spaced_weights"], [15, 3, 1, "", "extrema_weights"], [15, 3, 1, "", "get_grad_norm"], [15, 3, 1, "", "huber"], [15, 3, 1, "", "layer_init"], [15, 3, 1, "", "linearly_decaying_value"], [15, 3, 1, "", "log_episode_info"], [15, 3, 1, "", "make_gif"], [15, 3, 1, "", "polyak_update"], [15, 3, 1, "", "random_weights"]], "morl_baselines.multi_policy.envelope.envelope": [[2, 0, 1, "", "Envelope"]], "morl_baselines.multi_policy.envelope.envelope.Envelope": [[2, 1, 1, "", "act"], [2, 1, 1, "", "ddqn_target"], [2, 1, 1, "", "envelope_target"], [2, 1, 1, "", "eval"], [2, 1, 1, "", "get_config"], [2, 1, 1, "", "load"], [2, 1, 1, "", "max_action"], [2, 1, 1, "", "save"], [2, 1, 1, "", "train"], [2, 1, 1, "", "update"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd": [[3, 0, 1, "", "GPIPD"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD": [[3, 1, 1, "", "eval"], [3, 1, 1, "", "get_config"], [3, 1, 1, "", "gpi_action"], [3, 1, 1, "", "load"], [3, 1, 1, "", "max_action"], [3, 1, 1, "", "save"], [3, 1, 1, "", "set_weight_support"], [3, 1, 1, "", "train"], [3, 1, 1, "", "train_iteration"], [3, 1, 1, "", "update"]], "morl_baselines.multi_policy.linear_support.linear_support": [[4, 0, 1, "", "LinearSupport"]], "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport": [[4, 1, 1, "", "add_solution"], [4, 1, 1, "", "compute_corner_weights"], [4, 1, 1, "", "ended"], [4, 1, 1, "", "get_corner_weights"], [4, 1, 1, "", "get_weight_support"], [4, 1, 1, "", "gpi_ls_priority"], [4, 1, 1, "", "is_dominated"], [4, 1, 1, "", "max_scalarized_value"], [4, 1, 1, "", "max_value_lp"], [4, 1, 1, "", "next_weight"], [4, 1, 1, "", "ols_priority"], [4, 1, 1, "", "remove_obsolete_values"], [4, 1, 1, "", "remove_obsolete_weights"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning": [[5, 0, 1, "", "MPMOQLearning"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning": [[5, 1, 1, "", "delete_policies"], [5, 1, 1, "", "eval"], [5, 1, 1, "", "get_config"], [5, 1, 1, "", "train"], [5, 1, 1, "", "update"]], "morl_baselines.multi_policy.pareto_q_learning.pql": [[6, 0, 1, "", "PQL"]], "morl_baselines.multi_policy.pareto_q_learning.pql.PQL": [[6, 1, 1, "", "calc_non_dominated"], [6, 1, 1, "", "get_config"], [6, 1, 1, "", "get_local_pcs"], [6, 1, 1, "", "get_q_set"], [6, 1, 1, "", "score_hypervolume"], [6, 1, 1, "", "score_pareto_cardinality"], [6, 1, 1, "", "select_action"], [6, 1, 1, "", "track_policy"], [6, 1, 1, "", "train"]], "morl_baselines.multi_policy.pcn.pcn": [[7, 0, 1, "", "PCN"]], "morl_baselines.multi_policy.pcn.pcn.PCN": [[7, 1, 1, "", "eval"], [7, 1, 1, "", "evaluate"], [7, 1, 1, "", "get_config"], [7, 1, 1, "", "save"], [7, 1, 1, "", "set_desired_return_and_horizon"], [7, 1, 1, "", "train"], [7, 1, 1, "", "update"]], "morl_baselines.multi_policy.pgmorl.pgmorl": [[8, 0, 1, "", "PGMORL"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL": [[8, 1, 1, "", "get_config"], [8, 1, 1, "", "train"]], "morl_baselines.single_policy.esr.eupg": [[11, 0, 1, "", "EUPG"]], "morl_baselines.single_policy.esr.eupg.EUPG": [[11, 1, 1, "", "eval"], [11, 1, 1, "", "get_config"], [11, 1, 1, "", "train"], [11, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_q_learning": [[12, 0, 1, "", "MOQLearning"]], "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning": [[12, 1, 1, "", "eval"], [12, 1, 1, "", "get_config"], [12, 1, 1, "", "scalarized_q_values"], [12, 1, 1, "", "train"], [12, 1, 1, "", "update"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "titleterms": {"overview": [0, 21], "multi": [1, 9, 14, 20], "polici": [1, 9, 10], "algorithm": [1, 9, 10, 20], "envelop": 2, "q": [2, 6], "learn": [2, 5, 6, 12, 20], "gpi": 3, "priorit": [3, 14], "dyna": 3, "linear": 4, "support": 4, "mpmoq": 5, "pareto": [6, 7, 17], "condit": 7, "network": [7, 16], "pgmorl": 8, "perform": [9, 18], "assess": 9, "introduct": 9, "metric": 9, "storag": 9, "singl": [9, 10], "refer": 9, "eupg": 11, "moq": 12, "commun": 13, "maintain": 13, "contribut": 13, "acknowledg": 13, "replai": 14, "buffer": 14, "object": [14, 20], "divers": 14, "accru": 14, "reward": 14, "miscellan": 15, "neural": 16, "helper": 16, "util": 17, "indic": 18, "scalar": 19, "function": 19, "morl": 20, "baselin": 20, "A": 20, "collect": 20, "reinforc": 20, "featur": 20, "cite": 20}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Overview": [[0, "overview"], [21, "overview"]], "Multi-Policy Algorithms": [[1, "multi-policy-algorithms"]], "Envelope Q-Learning": [[2, "envelope-q-learning"]], "GPI-Prioritized Dyna": [[3, "gpi-prioritized-dyna"]], "Linear Support": [[4, "linear-support"]], "MPMOQ Learning": [[5, "mpmoq-learning"]], "Pareto Q-Learning": [[6, "pareto-q-learning"]], "Pareto Conditioned Networks": [[7, "pareto-conditioned-networks"]], "PGMORL": [[8, "pgmorl"]], "Performance assessments": [[9, "performance-assessments"]], "Introduction": [[9, "introduction"]], "Metrics": [[9, "metrics"]], "Storage": [[9, "storage"]], "Algorithms": [[9, "algorithms"]], "Single-policy algorithms": [[9, "single-policy-algorithms"]], "Multi-policy algorithms": [[9, "multi-policy-algorithms"]], "References": [[9, "references"]], "Single-policy Algorithms": [[10, "single-policy-algorithms"]], "EUPG": [[11, "eupg"]], "MOQ-Learning": [[12, "moq-learning"]], "Community": [[13, "community"]], "Maintainers": [[13, "maintainers"]], "Contributing": [[13, "contributing"]], "Acknowledgements": [[13, "acknowledgements"]], "Replay Buffers": [[14, "replay-buffers"]], "Multi-Objective Replay Buffer": [[14, "multi-objective-replay-buffer"]], "Diverse Replay Buffer": [[14, "diverse-replay-buffer"]], "Prioritized Replay Buffer": [[14, "prioritized-replay-buffer"]], "Accrued Reward Replay Buffer": [[14, "accrued-reward-replay-buffer"]], "Miscellaneous": [[15, "module-morl_baselines.common.utils"]], "Neural Networks helpers": [[16, "module-morl_baselines.common.networks"]], "Pareto utils": [[17, "module-morl_baselines.common.pareto"]], "Performance indicators": [[18, "module-morl_baselines.common.performance_indicators"]], "Scalarization functions": [[19, "module-morl_baselines.common.scalarization"]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[20, "morl-baselines-a-collection-of-multi-objective-reinforcement-learning-algorithms"]], "Features of MORL-Baselines": [[20, "features-of-morl-baselines"]], "Citing MORL-Baselines": [[20, "citing-morl-baselines"]]}, "indexentries": {"envelope (class in morl_baselines.multi_policy.envelope.envelope)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope"]], "act() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.act"]], "ddqn_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.ddqn_target"]], "envelope_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.envelope_target"]], "eval() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.eval"]], "get_config() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.get_config"]], "load() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.load"]], "max_action() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.max_action"]], "save() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.save"]], "train() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.train"]], "update() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[2, "morl_baselines.multi_policy.envelope.envelope.Envelope.update"]], "gpipd (class in morl_baselines.multi_policy.gpi_pd.gpi_pd)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD"]], "eval() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.eval"]], "get_config() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.get_config"]], "gpi_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.gpi_action"]], "load() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.load"]], "max_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.max_action"]], "save() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.save"]], "set_weight_support() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.set_weight_support"]], "train() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train"]], "train_iteration() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train_iteration"]], "update() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[3, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.update"]], "linearsupport (class in morl_baselines.multi_policy.linear_support.linear_support)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport"]], "add_solution() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.add_solution"]], "compute_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.compute_corner_weights"]], "ended() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ended"]], "get_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_corner_weights"]], "get_weight_support() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_weight_support"]], "gpi_ls_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.gpi_ls_priority"]], "is_dominated() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.is_dominated"]], "max_scalarized_value() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_scalarized_value"]], "max_value_lp() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_value_lp"]], "next_weight() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.next_weight"]], "ols_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ols_priority"]], "remove_obsolete_values() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_values"]], "remove_obsolete_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[4, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_weights"]], "mpmoqlearning (class in morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning"]], "delete_policies() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.delete_policies"]], "eval() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.eval"]], "get_config() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.get_config"]], "train() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.train"]], "update() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[5, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.update"]], "pql (class in morl_baselines.multi_policy.pareto_q_learning.pql)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL"]], "calc_non_dominated() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.calc_non_dominated"]], "get_config() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_config"]], "get_local_pcs() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_local_pcs"]], "get_q_set() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_q_set"]], "score_hypervolume() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_hypervolume"]], "score_pareto_cardinality() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_pareto_cardinality"]], "select_action() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.select_action"]], "track_policy() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.track_policy"]], "train() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[6, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.train"]], "pcn (class in morl_baselines.multi_policy.pcn.pcn)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN"]], "eval() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.eval"]], "evaluate() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.evaluate"]], "get_config() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.get_config"]], "save() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.save"]], "set_desired_return_and_horizon() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.set_desired_return_and_horizon"]], "train() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.train"]], "update() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[7, "morl_baselines.multi_policy.pcn.pcn.PCN.update"]], "pgmorl (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[8, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL"]], "get_config() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[8, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.get_config"]], "train() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[8, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.train"]], "eupg (class in morl_baselines.single_policy.esr.eupg)": [[11, "morl_baselines.single_policy.esr.eupg.EUPG"]], "eval() (morl_baselines.single_policy.esr.eupg.eupg method)": [[11, "morl_baselines.single_policy.esr.eupg.EUPG.eval"]], "get_config() (morl_baselines.single_policy.esr.eupg.eupg method)": [[11, "morl_baselines.single_policy.esr.eupg.EUPG.get_config"]], "train() (morl_baselines.single_policy.esr.eupg.eupg method)": [[11, "morl_baselines.single_policy.esr.eupg.EUPG.train"]], "update() (morl_baselines.single_policy.esr.eupg.eupg method)": [[11, "morl_baselines.single_policy.esr.eupg.EUPG.update"]], "moqlearning (class in morl_baselines.single_policy.ser.mo_q_learning)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning"]], "eval() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.eval"]], "get_config() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.get_config"]], "scalarized_q_values() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.scalarized_q_values"]], "train() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.train"]], "update() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[12, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.update"]], "accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[14, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer"]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory"]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer"]], "replaybuffer (class in morl_baselines.common.buffer)": [[14, "morl_baselines.common.buffer.ReplayBuffer"]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[14, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add"]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[14, "morl_baselines.common.buffer.ReplayBuffer.add"]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.add"]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add"]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample"]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree"]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[14, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup"]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe"]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace"]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.get"]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[14, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[14, "morl_baselines.common.buffer.ReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data"]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data"]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error"]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write"]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value"]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full"]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec"]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace"]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[14, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample"]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[14, "morl_baselines.common.buffer.ReplayBuffer.sample"]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.sample"]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample"]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[14, "morl_baselines.common.buffer.ReplayBuffer.sample_obs"]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs"]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances"]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[14, "morl_baselines.common.diverse_buffer.DiverseMemory.update"]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[14, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities"]], "equally_spaced_weights() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.equally_spaced_weights"]], "extrema_weights() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.extrema_weights"]], "get_grad_norm() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.get_grad_norm"]], "huber() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.huber"]], "layer_init() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.layer_init"]], "linearly_decaying_value() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.linearly_decaying_value"]], "log_episode_info() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.log_episode_info"]], "make_gif() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.make_gif"]], "module": [[15, "module-morl_baselines.common.utils"], [16, "module-morl_baselines.common.networks"], [17, "module-morl_baselines.common.pareto"], [18, "module-morl_baselines.common.performance_indicators"], [19, "module-morl_baselines.common.scalarization"]], "morl_baselines.common.utils": [[15, "module-morl_baselines.common.utils"]], "polyak_update() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.polyak_update"]], "random_weights() (in module morl_baselines.common.utils)": [[15, "morl_baselines.common.utils.random_weights"]], "naturecnn (class in morl_baselines.common.networks)": [[16, "morl_baselines.common.networks.NatureCNN"]], "forward() (morl_baselines.common.networks.naturecnn method)": [[16, "morl_baselines.common.networks.NatureCNN.forward"]], "mlp() (in module morl_baselines.common.networks)": [[16, "morl_baselines.common.networks.mlp"]], "morl_baselines.common.networks": [[16, "module-morl_baselines.common.networks"]], "paretoarchive (class in morl_baselines.common.pareto)": [[17, "morl_baselines.common.pareto.ParetoArchive"]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[17, "morl_baselines.common.pareto.ParetoArchive.add"]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[17, "morl_baselines.common.pareto.get_non_dominated"]], "get_non_dominated_inds() (in module morl_baselines.common.pareto)": [[17, "morl_baselines.common.pareto.get_non_dominated_inds"]], "morl_baselines.common.pareto": [[17, "module-morl_baselines.common.pareto"]], "expected_utility() (in module morl_baselines.common.performance_indicators)": [[18, "morl_baselines.common.performance_indicators.expected_utility"]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[18, "morl_baselines.common.performance_indicators.hypervolume"]], "maximum_utility_loss() (in module morl_baselines.common.performance_indicators)": [[18, "morl_baselines.common.performance_indicators.maximum_utility_loss"]], "morl_baselines.common.performance_indicators": [[18, "module-morl_baselines.common.performance_indicators"]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[18, "morl_baselines.common.performance_indicators.sparsity"]], "morl_baselines.common.scalarization": [[19, "module-morl_baselines.common.scalarization"]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[19, "morl_baselines.common.scalarization.tchebicheff"]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[19, "morl_baselines.common.scalarization.weighted_sum"]]}})