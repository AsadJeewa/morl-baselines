Search.setIndex({"docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/capql", "algos/multi_policy/envelope", "algos/multi_policy/gpi_pd", "algos/multi_policy/linear_support", "algos/multi_policy/morld", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pcn", "algos/multi_policy/pgmorl", "algos/performances", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/evaluations", "features/hpo", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "features/weights", "index", "quickstart/overview"], "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/capql.md", "algos/multi_policy/envelope.md", "algos/multi_policy/gpi_pd.md", "algos/multi_policy/linear_support.md", "algos/multi_policy/morld.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pcn.md", "algos/multi_policy/pgmorl.md", "algos/performances.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/evaluations.md", "features/hpo.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "features/weights.md", "index.md", "quickstart/overview.md"], "titles": ["Overview", "Multi-Policy Algorithms", "Concave-Augmented Pareto Q-Learning (CAPQL)", "Envelope Q-Learning", "GPI-Prioritized Dyna", "Linear Support", "MORL/D", "MPMOQ Learning", "Pareto Q-Learning", "Pareto Conditioned Networks", "PGMORL", "Performance assessments", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Evaluations", "Hyperparameter optimization", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "Weights helpers", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "terms": {"morl": [0, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 18, 19, 22, 26], "baselin": [0, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 15, 18, 19, 26], "contain": [0, 6, 16, 17, 18, 19, 25, 26], "multipl": [0, 3, 6, 10, 16, 17, 19], "implement": [0, 5, 6, 10, 11, 15, 16, 25, 26], "multi": [0, 2, 3, 4, 6, 7, 8, 10, 13, 14, 17, 18, 20, 22, 26], "object": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 22], "reinforc": [0, 2, 3, 6, 7, 8, 10, 11, 13, 14, 16, 18, 20], "learn": [0, 4, 6, 9, 10, 11, 13, 15, 16, 18, 20], "algorithm": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 18, 21, 22, 26], "The": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 18, 19, 20, 21, 25, 26], "follow": [0, 7, 11, 16, 18, 19, 20, 25, 26], "tabl": [0, 7, 11, 14], "list": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 16, 17, 19, 20, 21, 22, 24], "ar": [0, 5, 6, 10, 11, 15, 16, 18, 21, 22, 24, 25], "current": [0, 3, 5, 8, 10, 11, 15, 16, 17, 19, 20, 22], "name": [0, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 18], "singl": [0, 6, 14, 25, 26], "polici": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 17, 22, 25, 26], "esr": [0, 6, 13, 16, 17, 25, 26], "ser": [0, 6, 10, 14, 25, 26], "observ": [0, 2, 3, 9, 10, 13, 14, 16, 20], "space": [0, 10, 11, 24], "action": [0, 2, 3, 4, 7, 8, 9, 10, 13, 14, 16], "paper": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 18, 20, 22, 25], "gpi": [0, 2, 5, 7, 14], "l": [0, 4, 5, 7, 11, 22, 25], "pd": [0, 2, 4, 7, 14], "continu": [0, 2, 9, 10, 11], "discret": 0, "supplementari": [0, 10], "materi": [0, 10], "d": [0, 10, 11, 13, 18, 22], "envelop": [0, 18], "q": [0, 7, 14, 15, 18], "capql": 0, "pgmorl": [0, 11, 22], "1": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 19, 20, 24], "pareto": [0, 3, 4, 6, 7, 10, 11, 15, 17, 22, 25], "condit": [0, 2, 3, 13, 17], "network": [0, 2, 3, 4, 10, 13], "pcn": [0, 9, 15], "2": [0, 2, 4, 9, 10, 11, 16], "mo": [0, 7, 11, 14, 17, 25, 26], "mpmoqlearn": [0, 7, 14], "outer": [0, 7], "loop": [0, 7], "moql": 0, "optimist": [0, 5, 7], "linear": [0, 7, 13], "support": [0, 4, 6, 7, 10, 11, 25], "ol": [0, 5, 7], "section": [0, 5, 10], "3": [0, 5, 8, 10, 11, 18, 25], "thesi": [0, 5], "expect": [0, 2, 3, 4, 6, 7, 8, 9, 11, 13, 17, 22], "util": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 19, 20, 22, 24, 25], "gradient": [0, 2, 3, 4, 10, 13], "eupg": [0, 6, 15], "warn": [0, 5, 11], "some": [0, 10, 11, 22, 25], "have": [0, 10, 11, 15, 19, 21, 25], "limit": 0, "featur": [0, 15, 20], "i": [0, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "environ": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 19, 25, 26], "assum": 0, "determinist": 0, "transit": [0, 4, 16], "class": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 20, 21], "morl_baselin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24], "multi_polici": [2, 3, 4, 5, 6, 7, 8, 9, 10, 26], "env": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19], "learning_r": [2, 3, 4, 7, 9, 10, 13, 14], "float": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 22, 23], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 18, 19, 20, 24], "0003": [2, 3, 4, 10], "gamma": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "99": [2, 3, 4, 13], "tau": [2, 3, 4, 20, 23], "005": 2, "buffer_s": [2, 3, 4, 13], "int": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 22, 23, 24], "1000000": [2, 3, 4], "net_arch": [2, 3, 4, 10, 13, 20], "256": [2, 3, 4, 9], "batch_siz": [2, 3, 4, 9, 16], "128": [2, 4], "num_q_net": 2, "alpha": [2, 3, 4, 13, 14, 24], "learning_start": [2, 3, 4, 14], "1000": [2, 4, 7, 8, 13, 14], "gradient_upd": [2, 3, 4], "project_nam": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 19, 22, 24], "experiment_nam": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "wandb_ent": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "none": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 24], "log": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 17], "bool": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 21, 22], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 21, 22], "seed": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 24], "devic": [2, 3, 4, 6, 9, 10, 13, 16], "auto": [2, 3, 4, 6, 9, 10, 13], "convex": [2, 11, 21], "stationar": 2, "AND": 2, "optim": [2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 25], "haoy": 2, "lu": 2, "daniel": 2, "herman": 2, "yaoliang": 2, "yu": 2, "iclr": 2, "2023": [2, 4, 18, 25], "http": [2, 3, 4, 5, 9, 10, 11, 16, 21, 24, 25], "openreview": 2, "net": [2, 3, 10, 13, 20, 26], "pdf": [2, 5, 9, 10], "id": [2, 10, 13, 14, 16, 17, 18, 19], "tjezisyesq6": 2, "code": [2, 9, 10, 16, 21, 25], "base": [2, 6, 8, 10, 11, 13, 22, 25], "github": [2, 9, 10, 16], "com": [2, 9, 10, 16, 21], "haoyelu": 2, "It": [2, 11, 17, 18, 20, 23, 24, 25], "extend": 2, "soft": [2, 3, 4], "actor": [2, 10], "critic": [2, 10], "rl": [2, 6, 10, 22, 25], "weight": [2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 17, 19, 20, 22, 23, 25], "vector": [2, 3, 4, 5, 6, 8, 10, 17, 19, 20, 21, 22, 23, 24], "paramet": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24], "gym": [2, 4, 8, 9], "train": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 17, 18, 19], "option": [2, 3, 4, 5, 7, 8, 9, 13, 14, 17, 21], "rate": [2, 3, 4, 7, 9, 10, 13, 14, 20], "default": [2, 5, 8, 9, 10, 11, 16, 17, 18, 21, 22, 24], "3e": 2, "4": [2, 3, 10], "discount": [2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 17], "factor": [2, 3, 4, 7, 8, 9, 10, 13, 14], "updat": [2, 3, 4, 6, 7, 9, 10, 13, 14, 16, 20], "coeffici": [2, 3, 4, 10, 20], "size": [2, 3, 4, 6, 9, 10, 13, 16, 24], "replai": [2, 3, 4, 9, 13, 26], "buffer": [2, 3, 4, 6, 9, 10, 13, 25, 26], "1e6": 2, "architectur": [2, 4, 20], "batch": [2, 3, 4, 9, 16, 21], "number": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 24], "us": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 24, 25, 26], "entropi": [2, 10], "regular": 2, "step": [2, 3, 4, 7, 8, 9, 10, 14, 17, 19], "take": [2, 3, 17], "befor": [2, 3, 4, 10, 14, 19], "start": [2, 3, 4, 10, 13, 14, 16, 18], "100": [2, 3, 4, 7, 9, 10, 18], "per": [2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 17, 20], "project": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15], "experi": [2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 18, 25], "wandb": [2, 3, 4, 6, 8, 9, 10, 11, 13, 19, 25], "entiti": [2, 3, 4, 7, 8, 9, 10, 13, 14], "whether": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 21], "union": [2, 9], "th": [2, 9], "eval": [2, 3, 4, 7, 9, 10, 11, 13, 14], "ob": [2, 3, 4, 5, 7, 9, 10, 13, 14, 16], "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 17, 19, 20, 21, 22, 23, 24], "tensor": [2, 3, 4, 16, 20], "w": [2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17], "torch_act": 2, "fals": [2, 3, 4, 5, 6, 7, 10, 14, 16, 17, 18, 20, 21], "evalu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 21], "given": [2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 20], "get_config": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "get": [2, 5, 7, 8, 9, 15, 16], "configur": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14], "agent": [2, 3, 4, 5, 9, 10, 11, 13, 14, 17, 19], "load": [2, 3, 4], "path": [2, 3, 4], "load_replay_buff": [2, 3, 4], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25], "file": [2, 18, 26], "save": [2, 3, 4, 9, 19], "save_dir": [2, 3, 4], "filenam": [2, 3, 4, 9], "save_replay_buff": [2, 3, 4], "": [2, 3, 10, 11, 13, 16, 17, 24, 26], "total_timestep": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 18], "eval_env": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "ref_point": [2, 3, 4, 6, 7, 8, 9, 10, 22], "known_pareto_front": [2, 3, 4, 6, 7, 8, 9, 10], "num_eval_weights_for_front": [2, 3, 4, 7, 18], "num_eval_episodes_for_front": [2, 3, 4, 6, 7], "5": [2, 3, 4, 6, 7, 10, 14, 17], "num_eval_weights_for_ev": [2, 3, 4, 6, 7, 8, 9, 10], "50": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 19], "eval_freq": [2, 3, 4, 7, 13, 14, 18], "10000": [2, 3, 4, 8, 18], "reset_num_timestep": [2, 3, 4, 6, 14, 18], "checkpoint": [2, 4], "total": [2, 3, 6, 7, 9], "timestep": [2, 3, 4, 6, 7, 8, 13, 14, 17], "np": [2, 3, 4, 5, 9, 13, 14, 17, 19, 22], "refer": [2, 3, 4, 6, 7, 8, 9, 10, 17, 18, 22, 23], "point": [2, 3, 4, 6, 7, 8, 9, 10, 11, 17, 18, 21, 22, 23], "hypervolum": [2, 3, 4, 6, 7, 8, 9, 11, 17, 18, 22], "calcul": [2, 4, 7, 9, 21], "front": [2, 3, 4, 6, 7, 8, 9, 11, 17, 21, 22], "known": [2, 3, 4, 6, 7, 8, 9, 17, 22], "episod": [2, 3, 4, 6, 7, 8, 9, 13, 17, 19], "run": [2, 3, 4, 7, 10, 11, 13, 17, 19, 25], "when": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 19], "e": [2, 3, 4, 6, 7, 8, 9, 10, 13, 16, 17, 18, 22, 25], "g": [2, 3, 4, 6, 7, 8, 9, 10, 13, 18, 22, 25], "comput": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 19, 20, 21, 22], "between": [2, 4, 6, 11, 14, 22], "dure": [2, 8, 10], "an": [2, 3, 4, 5, 8, 10, 11, 15, 17, 18, 19, 20, 25], "iter": [2, 4, 5, 7, 10, 20], "reset": [2, 3, 4, 6, 14, 19], "initial_epsilon": [3, 4, 7, 8, 14], "01": [3, 4, 16, 20], "final_epsilon": [3, 4, 7, 8, 14], "epsilon_decay_step": [3, 4, 7, 8, 14], "target_net_update_freq": [3, 4], "200": [3, 18], "max_grad_norm": [3, 4, 10], "num_sample_w": 3, "per_alpha": 3, "6": [3, 4, 6, 10, 14], "initial_homotopy_lambda": 3, "final_homotopy_lambda": 3, "homotopy_decay_step": 3, "group": [3, 10], "lean": [3, 18], "emb": 3, "input": [3, 4, 20, 21], "main": [3, 10, 15, 16, 17], "chang": [3, 4, 10, 11, 21], "thi": [3, 5, 6, 9, 10, 11, 15, 16, 17, 19, 20, 21, 23, 25, 26], "compar": [3, 6], "scalar": [3, 5, 6, 7, 10, 11, 13, 14, 17], "cn": 3, "dqn": [3, 19, 20], "target": [3, 4, 10, 16, 20], "r": [3, 22], "yang": 3, "x": [3, 20], "sun": 3, "k": [3, 7, 8, 14], "narasimhan": 3, "A": [3, 7, 8, 9, 10, 11, 13, 14, 16, 18, 19, 21, 22], "gener": [3, 4, 5, 6, 7, 11, 13, 14, 17, 19, 22, 24], "adapt": [3, 6, 10, 23], "arxiv": [3, 4, 5, 18], "1908": 3, "08342": 3, "c": [3, 4, 11, 25], "nov": [3, 10, 11], "2019": 3, "access": 3, "sep": 3, "06": 3, "2021": 3, "onlin": 3, "avail": [3, 9, 10, 11, 16, 18, 25], "org": [3, 4, 5, 9, 24], "ab": [3, 4, 5], "initi": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 20, 21], "epsilon": [3, 4, 5, 7, 8, 14, 16, 19], "valu": [3, 4, 5, 7, 8, 10, 11, 14, 16, 17, 18, 19, 22, 23], "greedi": [3, 4, 14], "explor": 3, "final": [3, 4, 7, 8, 11, 14, 19], "decai": [3, 4, 7, 8, 14, 19], "over": [3, 7, 14, 19], "keep": [3, 10], "frequenc": [3, 4, 7, 13], "which": [3, 5, 6, 10, 11, 16, 19, 20, 21, 25], "hidden": [3, 9], "layer": [3, 4, 10, 13, 20], "sampl": [3, 4, 6, 9, 10, 16, 17, 24], "random": [3, 4, 6, 7, 8, 10, 13, 14, 17, 24], "until": [3, 19], "maximum": [3, 4, 5, 7, 9, 10, 11, 16, 17, 22], "norm": [3, 4, 10, 20], "clip": [3, 9, 10], "If": [3, 5, 7, 8, 14, 15, 16, 17, 25], "appli": [3, 6, 10, 16], "method": [3, 5, 6, 7, 8, 11, 14, 16, 20, 24], "priorit": [3, 7, 14], "homotopi": 3, "act": 3, "greedili": 3, "select": [3, 4, 7, 8, 10], "return": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25], "integ": 3, "repres": [3, 20], "ddqn_target": 3, "doubl": 3, "envelope_target": 3, "sampled_w": 3, "set": [3, 4, 5, 6, 7, 8, 9, 11, 13, 16, 17, 18, 21, 22, 25, 26], "give": [3, 13, 14, 16], "best": [3, 7, 10, 13, 14, 23], "arrai": [3, 7, 10, 13, 14, 16, 19, 21, 25], "dictionari": [3, 6, 7, 8, 10, 13, 14, 16, 17], "dict": [3, 6, 7, 8, 9, 10, 13, 14, 17], "config": [3, 6, 7, 10, 13, 14, 18], "model": [3, 4, 9, 14], "specifi": [3, 16, 18], "too": 3, "max_act": [3, 4], "highest": [3, 5], "directori": [3, 18, 19], "total_episod": 3, "reset_learning_start": [3, 4], "verbos": [3, 5, 17], "ignor": 3, "randomli": 3, "everi": [3, 8, 13], "done": [3, 16], "time": [3, 5, 6, 9, 10, 13, 14], "creat": [3, 14, 20], "print": [3, 5, 17], "info": [3, 5, 17], "gpi_pd": [4, 7, 14], "gpipd": 4, "type": [4, 6, 9, 16, 20, 22], "num_net": 4, "20": [4, 9, 10], "use_gpi": [4, 7], "alpha_p": 4, "min_prior": [4, 14, 16, 20], "drop_rat": [4, 20], "layer_norm": [4, 20], "dynamics_normalize_input": 4, "dynamics_uncertainty_threshold": 4, "dynamics_train_freq": 4, "callabl": [4, 6, 8, 13, 19, 22, 23], "function": [4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 20, 21, 22, 25], "lambda": [4, 6, 10, 16], "dynamics_rollout_len": 4, "dynamics_rollout_start": 4, "5000": 4, "dynamics_rollout_freq": 4, "250": 4, "dynamics_rollout_batch_s": 4, "25000": 4, "dynamics_buffer_s": 4, "100000": [4, 8, 13, 16], "dynamics_net_arch": 4, "dynamics_ensemble_s": 4, "dynamics_num_elit": 4, "real_ratio": 4, "torch": [4, 6, 20], "effici": [4, 6], "via": 4, "improv": [4, 5, 6, 7, 14], "luca": [4, 15, 25], "n": [4, 9, 13, 15, 16, 19, 24, 25], "alegr": [4, 15, 25], "ana": [4, 25], "bazzan": [4, 25], "diederik": 4, "m": [4, 7, 9, 11, 14, 22], "roijer": [4, 5, 11, 13, 22], "ann": [4, 25], "now\u00e9": [4, 8, 9], "bruno": [4, 25], "da": [4, 25], "silva": [4, 25], "aama": 4, "2301": [4, 5], "07784": [4, 5], "minimum": [4, 5, 10, 14, 16, 20], "prioriti": [4, 5, 14, 16, 20], "dropout": [4, 20], "normal": [4, 10, 16, 20, 24], "dynam": 4, "uncertainti": 4, "threshold": [4, 10], "rollout": 4, "length": [4, 19, 20], "first": [4, 21], "ensembl": 4, "elit": 4, "ratio": 4, "real": 4, "gpi_act": 4, "return_policy_index": 4, "include_w": 4, "set_weight_support": 4, "weight_list": 4, "timesteps_per_it": 4, "weight_selection_algo": [4, 7], "eval_mo_freq": 4, "train_iter": 4, "weight_support": 4, "change_w_every_episod": 4, "one": [4, 6, 14, 17, 22, 24], "end": [4, 5, 16], "each": [4, 6, 10, 11, 14, 16, 18, 20, 22, 23], "linear_support": 5, "linearsupport": 5, "num_object": 5, "corner": 5, "both": [5, 11, 25], "pub": 5, "add_solut": 5, "add": [5, 9, 10, 16, 21], "new": [5, 7, 10, 13, 14, 15, 16], "indic": [5, 7, 16, 21], "remov": [5, 16, 21], "cc": [5, 11], "being": 5, "domin": [5, 8, 21, 23], "compute_corner_weight": 5, "see": [5, 6, 10, 26], "definit": [5, 25], "19": 5, "typo": 5, "sign": 5, "should": [5, 6, 10, 16, 17, 21], "more": [5, 6, 10, 26], "test": [5, 11, 25], "must": 5, "call": [5, 17], "after": [5, 6, 10, 20], "next_weight": 5, "ex": 5, "get_corner_weight": 5, "top_k": 5, "get_weight_support": 5, "gpi_ls_prior": 5, "gpi_expanded_set": 5, "is_domin": 5, "check": [5, 16], "ani": [5, 22], "otherwis": [5, 7, 19], "max_scalarized_valu": 5, "max_value_lp": 5, "w_new": 5, "upper": 5, "bound": 5, "algo": [5, 18], "gpi_ag": 5, "mopolici": 5, "rep_ev": 5, "next": [5, 10, 16], "either": [5, 24], "ols_prior": 5, "remove_obsolete_valu": 5, "longer": 5, "ad": [5, 16], "remove_obsolete_weight": 5, "new_valu": 5, "queue": 5, "better": 5, "than": [5, 10], "previou": [5, 7, 16], "decomposit": [6, 25], "idea": [6, 11, 13, 15], "framework": [6, 25], "decompos": 6, "problem": [6, 11, 18, 22], "solv": 6, "someth": [6, 10], "close": 6, "There": 6, "trick": 6, "can": [6, 11, 13, 15, 19, 25], "just": 6, "sequenti": [6, 20], "detail": [6, 10, 25, 26], "morld": 6, "gymnasium": [6, 11, 17, 25, 26], "core": 6, "scalarization_method": 6, "evaluation_mod": 6, "policy_nam": 6, "mosac": 6, "policy_arg": 6, "995": [6, 10], "pop_siz": [6, 10], "42": [6, 10, 24], "rng": [6, 10, 24], "numpi": [6, 10, 14, 16, 17, 21, 22, 23, 25], "_gener": [6, 14], "exchange_everi": 6, "40000": 6, "neighborhood_s": 6, "dist_metr": [6, 19], "shared_buff": 6, "sharing_mechan": 6, "update_pass": 6, "10": [6, 7, 9, 10, 11, 14, 18], "weight_init_method": 6, "uniform": 6, "weight_adaptation_method": 6, "techniqu": [6, 7, 14, 25], "tch": 6, "underli": 6, "easili": 6, "argument": 6, "popul": [6, 10], "exchang": 6, "trigger": 6, "neighbordhood": 6, "distanc": [6, 11, 16, 17, 19, 22], "metric": [6, 7, 8, 9, 17, 19, 22], "determin": [6, 10, 16], "neighborhood": [6, 10], "share": [6, 13], "potenti": [6, 13], "mechan": 6, "transfer": 6, "onli": [6, 17, 22, 25], "now": [6, 7, 10, 13, 14, 25], "all": [6, 7, 9, 11, 15, 16, 17, 19, 21, 25, 26], "psa": 6, "For": [6, 11, 18, 25], "multi_policy_moqlearn": 7, "mp_mo_q_learn": 7, "weighted_sum": [7, 14, 23], "9": [7, 14], "epsilon_ol": 7, "use_gpi_polici": [7, 14], "transfer_q_t": 7, "dyna": [7, 14], "dyna_upd": [7, 14], "multipolici": 7, "moq": 7, "version": [7, 21], "mo_q_learn": [7, 14], "van": [7, 8, 14], "moffaert": [7, 8, 14], "drugan": [7, 14], "novel": [7, 14], "design": [7, 14, 25], "2013": [7, 14], "doi": [7, 11, 14, 18], "1109": [7, 14], "adprl": [7, 14], "6615007": [7, 14], "reus": 7, "perform": [7, 10, 14, 25], "reproduc": [7, 9, 11, 13, 17, 25], "delete_polici": 7, "delete_indx": 7, "delet": 7, "choos": [7, 14], "max_scalar_q_valu": 7, "state": [7, 8, 17, 22], "timesteps_per_iter": 7, "200000": 7, "construct": 7, "pareto_q_learn": 8, "pql": 8, "8": 8, "tabular": 8, "reli": [8, 10, 11, 14, 22, 23], "prune": [8, 21, 25], "journal": 8, "machin": [8, 10, 11], "research": [8, 25], "vol": [8, 11], "15": 8, "pp": [8, 9, 10, 11], "3483": 8, "3512": 8, "2014": 8, "calc_non_domin": 8, "non": [8, 13, 21], "get_local_pc": 8, "collect": [8, 10, 20], "local": 8, "pc": 8, "get_q_set": 8, "pair": [8, 16], "score_hypervolum": 8, "score": 8, "upon": 8, "score_pareto_cardin": 8, "cardin": [8, 11, 22], "select_act": 8, "score_func": 8, "track_polici": 8, "vec": 8, "tol": [8, 19], "001": [8, 9, 13], "track": [8, 11, 25], "its": [8, 16, 21, 22], "array_lik": 8, "toler": [8, 19], "1e": [8, 9, 16], "log_everi": [8, 13], "action_ev": 8, "eval_ref_point": 8, "same": [8, 16, 18, 19], "ref": [8, 18], "result": [8, 10, 11, 25], "scaling_factor": 9, "hidden_dim": 9, "64": [9, 10], "nois": 9, "model_class": 9, "basepcnmodel": 9, "reymond": [9, 15], "bargiacchi": 9, "2022": [9, 11], "mai": 9, "In": [9, 11], "proceed": [9, 10, 11, 25], "21st": 9, "intern": [9, 10, 11], "confer": [9, 10, 11, 25], "autonom": [9, 11], "multiag": 9, "system": [9, 11, 25], "1110": 9, "1118": 9, "www": 9, "ifaama": 9, "aamas2022": 9, "p1110": 9, "credit": 9, "refactor": [9, 10], "author": [9, 10, 25], "mathieu": [9, 15], "scale": [9, 10], "desir": 9, "horizon": 9, "32": [9, 10], "dimens": [9, 16, 20, 23], "standard": [9, 25], "deviat": 9, "case": [9, 14], "max_return": 9, "pcn_model": 9, "savedir": 9, "set_desired_return_and_horizon": 9, "desired_return": 9, "desired_horizon": 9, "num_er_episod": 9, "num_step_episod": 9, "num_model_upd": 9, "max_buffer_s": 9, "num_points_pf": 9, "fill": [9, 16, 17], "ha": [10, 17, 18], "been": [10, 19, 21, 25], "origin": [10, 11, 15], "provid": [10, 15, 16, 17, 21, 25], "post": 10, "process": [10, 17, 25], "phase": 10, "analysi": [10, 11], "stage": 10, "yet": 10, "ppo": 10, "look": 10, "variou": [10, 11, 15, 22, 25], "tradeoff": 10, "along": [10, 11], "At": 10, "few": 10, "assign": 10, "further": 10, "histor": 10, "data": [10, 16], "gather": 10, "our": [10, 11, 15, 25], "essenti": 10, "cleanrl": [10, 25], "differ": [10, 18, 25], "sum": [10, 23], "note": 10, "might": 10, "possibl": [10, 11, 19, 26], "enhanc": 10, "els": 10, "single_polici": [10, 13, 14, 26], "mo_ppo": 10, "mopponet": 10, "syncvectorenv": 10, "steps_per_iter": 10, "2048": 10, "num_minibatch": 10, "update_epoch": 10, "anneal_lr": 10, "clip_coef": 10, "ent_coef": 10, "vf_coef": 10, "clip_vloss": 10, "norm_adv": 10, "target_kl": 10, "gae": 10, "gae_lambda": 10, "95": 10, "modifi": 10, "clean": 10, "vwxyzjn": 10, "blob": 10, "master": 10, "ppo_continuous_act": 10, "py": [10, 11, 18], "minibatch": 10, "epoch": 10, "anneal": 10, "loss": [10, 11, 17, 20, 22], "advantag": 10, "kl": 10, "diverg": 10, "estim": 10, "change_weight": 10, "new_weight": 10, "start_tim": [10, 13, 14], "current_iter": 10, "max_iter": 10, "self": 10, "num_env": 10, "performancepredictor": 10, "neighborhood_threshold": 10, "sigma": 10, "03": 10, "a_bound_min": 10, "a_bound_max": 10, "500": 10, "f_scale": 10, "store": [10, 16], "delta": 10, "Then": 10, "regress": 10, "predictor": 10, "eval_before_pg": 10, "eval_after_pg": 10, "predict_next_evalu": 10, "weight_candid": 10, "policy_ev": 10, "tupl": [10, 16, 17], "part": 10, "whose": [10, 16], "candid": [10, 21], "env_id": 10, "warmup_iter": 10, "80": 10, "evolutionary_iter": 10, "num_weight_candid": 10, "7": 10, "num_performance_buff": 10, "performance_buffer_s": 10, "min_weight": 10, "max_weight": 10, "delta_weight": 10, "guid": [10, 11, 25], "j": [10, 11], "xu": [10, 11], "y": [10, 11], "tian": [10, 11], "p": [10, 11, 22], "ma": [10, 11], "ru": [10, 11], "sueda": [10, 11], "matusik": [10, 11], "robot": [10, 11], "control": [10, 11, 20], "37th": [10, 11, 25], "2020": [10, 11], "10607": [10, 11], "10616": [10, 11], "mlr": [10, 11], "press": [10, 11], "v119": [10, 11], "xu20h": [10, 11], "html": [10, 11, 24], "peopl": [10, 15], "csail": 10, "mit": 10, "edu": 10, "jiex": 10, "supp": 10, "make": [10, 17], "posit": [10, 16], "vectorizedenv": 10, "warmup": 10, "evolutionari": 10, "usual": [10, 20], "unit": [10, 13, 20], "term": [10, 11], "document": [11, 25, 26], "work": 11, "progress": 11, "To": 11, "ensur": 11, "correct": 11, "we": [11, 15, 16, 19, 22, 25], "want": [11, 15, 19], "them": [11, 15], "sake": 11, "mainten": 11, "purpos": 11, "long": 11, "conduct": 11, "henc": 11, "abl": 11, "were": 11, "present": 11, "keyword": 11, "scalarized_return": 11, "scalarized_discounted_return": 11, "propos": 11, "qualiti": [11, 22], "pf": [11, 22], "coverag": [11, 21], "converg": 11, "divers": 11, "hybrid": 11, "common": [11, 14, 16, 17, 19, 20, 21, 22, 23, 24, 26], "performance_ind": [11, 22], "sparsiti": [11, 17, 22], "averag": [11, 17, 20, 22], "consecut": 11, "igd": [11, 17, 22], "sota": 11, "moo": [11, 22], "literatur": 11, "requir": [11, 22, 23], "posteriori": 11, "That": [11, 24], "do": 11, "merg": 11, "found": [11, 25], "respect": 11, "moreov": 11, "assumpt": [11, 17], "user": 11, "These": [11, 16], "allow": 11, "wherea": 11, "other": [11, 14, 16, 25], "eum": [11, 17, 22], "mul": [11, 17, 22], "know": [11, 16, 22], "equal": [11, 24], "simplex": [11, 24], "also": [11, 15, 17, 25], "here": [11, 15, 25], "offici": 11, "sent": 11, "openrlbenchmark": [11, 25], "api": [11, 25], "queri": 11, "plot": 11, "format": [11, 25], "life": 11, "good": 11, "full": [11, 16], "flow": 11, "autom": 11, "cli": 11, "accordingli": 11, "locat": 11, "launch_experi": [11, 18], "below": [11, 16], "issu": [11, 15, 25], "predict": [11, 20], "hay": [11, 15], "et": [11, 19, 20], "al": [11, 19, 20], "practic": [11, 25], "plan": [11, 25], "36": 11, "apr": 11, "1007": 11, "s10458": 11, "022": 11, "09552": 11, "zintgraf": [11, 22], "t": [11, 22], "v": [11, 22], "kanter": [11, 22], "f": [11, 15, 18, 22], "oliehoek": [11, 22], "beau": [11, 22], "approach": [11, 22], "2015": [11, 19, 20, 22], "parent_rng": [13, 14], "accru": [13, 17], "reward": [13, 17, 23, 25], "futur": 13, "steckelmach": [13, 15], "2018": 13, "nn": [13, 20], "cpu": 13, "cuda": 13, "parent": [13, 14], "accrued_reward": [13, 16], "get_buff": 13, "pointer": 13, "get_policy_net": 13, "modul": [13, 20], "set_buff": 13, "pass": 13, "set_weight": 13, "sp": 13, "moqlearn": 14, "model_bas": 14, "tabular_model": 14, "tabularmodel": 14, "0001": [14, 19], "maintain": 14, "move": [14, 16], "wait": 14, "smooth": 14, "scalarized_q_valu": 14, "500000": 14, "max": 14, "recal": 14, "launch": [14, 18], "discord": 15, "server": 15, "where": [15, 19], "you": [15, 25], "ask": 15, "question": [15, 21], "help": 15, "repositori": [15, 25], "join": 15, "florian": [15, 25], "felten": [15, 18, 25], "ffelten": 15, "lucasalegr": 15, "open": [15, 25], "alwai": [15, 23], "happi": 15, "receiv": 15, "bug": 15, "fix": 15, "discuss": [15, 18], "your": [15, 25], "u": 15, "pull": 15, "request": 15, "directli": 15, "asid": 15, "contributor": 15, "mani": 15, "who": 15, "wai": [15, 16], "would": 15, "like": 15, "thank": 15, "willem": 15, "r\u00f6pke": 15, "hi": 15, "wilrop": 15, "deni": 15, "conor": 15, "librari": [16, 25], "replaybuff": 16, "obs_shap": 16, "action_dim": 16, "rew_dim": 16, "max_siz": 16, "obs_dtyp": 16, "float32": 16, "action_dtyp": 16, "shape": [16, 20], "next_ob": 16, "get_all_data": 16, "max_sampl": 16, "replac": 16, "use_c": 16, "to_tensor": 16, "cer": 16, "convert": 16, "pytorch": [16, 25], "sample_ob": 16, "diverse_buff": 16, "diversememori": 16, "main_capac": 16, "sec_capac": 16, "trace_divers": 16, "crowding_divers": 16, "value_funct": 16, "integr": 16, "secondari": 16, "extract": [16, 20], "axelabel": 16, "dynmorl": 16, "capac": 16, "enforc": [16, 25], "trace": 16, "level": [16, 20], "crowd": 16, "error": 16, "power": 16, "rais": 16, "reduc": 16, "without": 16, "trace_id": 16, "pred_idx": 16, "tree_id": 16, "proport": 16, "treat": 16, "identifi": 16, "tree": 16, "relev": 16, "index": 16, "node": 16, "wa": 16, "add_sampl": 16, "write": 16, "add_tre": 16, "dupe": 16, "trg_i": 16, "src_i": 16, "copi": 16, "sourc": [16, 21], "extract_trac": 16, "those": 16, "get_data": 16, "include_indic": 16, "includ": 16, "get_error": 16, "idx": 16, "correspond": [16, 20], "get_sec_writ": 16, "secondary_trac": 16, "reserved_idx": 16, "find": 16, "free": 16, "spot": 16, "memori": [16, 21], "recurs": 16, "past": 16, "low": 16, "get_trace_valu": 16, "trace_tupl": 16, "main_mem_is_ful": 16, "becaus": 16, "circular": 16, "suffici": 16, "move_to_sec": 16, "span": 16, "remove_trac": 16, "sec_dist": 16, "prioritized_buff": 16, "prioritizedreplaybuff": 16, "05": 16, "update_prior": 16, "accrued_reward_buff": 16, "accruedrewardreplaybuff": 16, "action_shap": 16, "cleanup": 16, "whole": 16, "element": [16, 19, 21, 24], "relat": [17, 24], "eval_mo": 17, "dot": [17, 22, 23], "render": [17, 19], "linearreward": 17, "wrapper": 17, "eval_mo_reward_condit": 17, "log_all_multi_policy_metr": 17, "current_front": 17, "hv_ref_point": 17, "reward_dim": [17, 23], "global_step": 17, "n_sample_weight": 17, "ref_front": 17, "invert": [17, 22], "approxim": [17, 22], "global": 17, "log_episode_info": 17, "global_timestep": 17, "inform": [17, 25], "last": [17, 20], "automat": [17, 23, 25], "recordstatisticswrapp": 17, "statist": 17, "policy_evaluation_mo": 17, "rep": 17, "avg": 17, "seed_everyth": 17, "onc": 17, "python": [17, 18, 21], "prefer": 17, "begin": [17, 19], "script": [17, 18], "effect": 17, "so": [17, 18, 19, 23], "care": 17, "earli": 18, "solut": [18, 21], "introduc": 18, "gareev": 18, "talbi": [18, 25], "danoi": [18, 25], "oct": 18, "25": 18, "48550": 18, "2310": 18, "16487": 18, "sweep": [18, 19], "benchmark": 18, "exampl": [18, 25, 26], "usag": 18, "hyperparameter_search": 18, "launch_sweep": 18, "minecart": 18, "v0": 18, "count": 18, "num": 18, "hyperparam": 18, "hp": 18, "search": 18, "try": [18, 19], "distribut": [18, 24], "yaml": 18, "11": 18, "12": 18, "linearly_decaying_valu": 19, "initial_valu": 19, "decay_period": 19, "warmup_step": 19, "final_valu": 19, "linearli": 19, "natur": [19, 20], "schedul": 19, "mnih": [19, 20], "taken": 19, "period": 19, "complet": 19, "far": [19, 23], "accord": 19, "make_gif": 19, "fullpath": 19, "fp": 19, "300": 19, "gif": 19, "nearest_neighbor": 19, "current_weight": 19, "all_weight": 19, "closest": 19, "neighbor": 19, "similar": [19, 22], "nearest": [19, 22], "well": [19, 25], "reset_wandb_env": 19, "variabl": 19, "parallel": 19, "unique_tol": 19, "uniqu": 19, "within": 19, "naturecnn": 20, "observation_shap": 20, "features_dim": 20, "512": 20, "cnn": 20, "volodymyr": 20, "human": 20, "through": 20, "deep": 20, "518": 20, "7540": 20, "529": 20, "533": 20, "forward": 20, "get_grad_norm": 20, "param": 20, "how": 20, "grad": 20, "insid": 20, "clip_grad_norm_": 20, "huber": 20, "layer_init": 20, "orthogon": 20, "weight_gain": 20, "bias_const": 20, "gain": 20, "constant": 20, "bia": 20, "mlp": 20, "input_dim": 20, "output_dim": 20, "activation_fn": 20, "activ": 20, "relu": 20, "perceptron": 20, "fulli": 20, "connect": 20, "output": 20, "polyak_upd": 20, "target_param": 20, "polyak": 20, "small": 20, "paretoarch": 21, "convex_hul": 21, "archiv": 21, "ineffici": 21, "filter_convex_domin": 21, "fast": 21, "hull": 21, "leverag": 21, "quickhul": 21, "filter_pareto_domin": 21, "remove_dupl": 21, "duplic": 21, "get_non_domin": 21, "subset": 21, "stackoverflow": 21, "32791911": 21, "answer": 21, "wrong": 21, "import": 21, "made": [21, 22], "get_non_dominated_ind": 21, "boolean": 21, "get_non_pareto_dominated_ind": 21, "kept": 21, "form": 21, "mostli": 22, "pymoo": [22, 24], "axiomat": 22, "hv": 22, "customli": 22, "expected_util": 22, "weights_set": 22, "But": 22, "need": 22, "assess": 22, "product": [22, 23], "_supportsarrai": 22, "dtype": 22, "_nestedsequ": 22, "complex": 22, "byte": 22, "known_front": 22, "current_estim": 22, "maximum_utility_loss": 22, "reference_set": 22, "basic": 22, "tchebicheff": 23, "seen": 23, "compon": 23, "sure": 23, "equally_spaced_weight": 24, "dim": 24, "riesz": 24, "energi": 24, "misc": 24, "reference_direct": 24, "extrema_weight": 24, "extrema": 24, "rest": 24, "random_weight": 24, "dist": 24, "dirichlet": 24, "gaussian": 24, "equival": 24, "uniformli": 24, "aim": 25, "reliabl": 25, "strictli": 25, "mdp": 25, "momdp": 25, "suggest": 25, "read": 25, "overview": 25, "taxonomi": 25, "tutori": 25, "under": 25, "criteria": 25, "report": 25, "bias": 25, "dashboard": 25, "lint": 25, "pre": 25, "commit": 25, "hook": 25, "etc": [25, 26], "manner": 25, "hyperparamet": 25, "particip": 25, "popular": 25, "stabl": 25, "ai": 25, "43": 25, "experiment": 25, "protocol": 25, "websit": 25, "pleas": 25, "neurip": 25, "inproceed": 25, "felten_toolkit_2023": 25, "el": 25, "ghazali": 25, "gr": 25, "goir": 25, "castro": 25, "titl": 25, "toolkit": 25, "booktitl": 25, "neural": [25, 26], "year": 25, "As": 26, "much": 26, "repo": 26, "tri": 26, "rule": 26, "structur": 26, "recur": 26, "concept": 26}, "objects": {"morl_baselines.common.accrued_reward_buffer": [[16, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "cleanup"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[16, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[16, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[16, 1, 1, "", "add"], [16, 1, 1, "", "add_sample"], [16, 1, 1, "", "add_tree"], [16, 1, 1, "", "dupe"], [16, 1, 1, "", "extract_trace"], [16, 1, 1, "", "get"], [16, 1, 1, "", "get_data"], [16, 1, 1, "", "get_error"], [16, 1, 1, "", "get_sec_write"], [16, 1, 1, "", "get_trace_value"], [16, 1, 1, "", "main_mem_is_full"], [16, 1, 1, "", "move_to_sec"], [16, 1, 1, "", "remove_trace"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sec_distances"], [16, 1, 1, "", "update"]], "morl_baselines.common": [[17, 2, 0, "-", "evaluation"], [20, 2, 0, "-", "networks"], [21, 2, 0, "-", "pareto"], [22, 2, 0, "-", "performance_indicators"], [23, 2, 0, "-", "scalarization"], [19, 2, 0, "-", "utils"], [24, 2, 0, "-", "weights"]], "morl_baselines.common.evaluation": [[17, 3, 1, "", "eval_mo"], [17, 3, 1, "", "eval_mo_reward_conditioned"], [17, 3, 1, "", "log_all_multi_policy_metrics"], [17, 3, 1, "", "log_episode_info"], [17, 3, 1, "", "policy_evaluation_mo"], [17, 3, 1, "", "seed_everything"]], "morl_baselines.common.networks": [[20, 0, 1, "", "NatureCNN"], [20, 3, 1, "", "get_grad_norm"], [20, 3, 1, "", "huber"], [20, 3, 1, "", "layer_init"], [20, 3, 1, "", "mlp"], [20, 3, 1, "", "polyak_update"]], "morl_baselines.common.networks.NatureCNN": [[20, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[21, 0, 1, "", "ParetoArchive"], [21, 3, 1, "", "filter_convex_dominated"], [21, 3, 1, "", "filter_pareto_dominated"], [21, 3, 1, "", "get_non_dominated"], [21, 3, 1, "", "get_non_dominated_inds"], [21, 3, 1, "", "get_non_pareto_dominated_inds"]], "morl_baselines.common.pareto.ParetoArchive": [[21, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[22, 3, 1, "", "cardinality"], [22, 3, 1, "", "expected_utility"], [22, 3, 1, "", "hypervolume"], [22, 3, 1, "", "igd"], [22, 3, 1, "", "maximum_utility_loss"], [22, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[16, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sample_obs"], [16, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[23, 3, 1, "", "tchebicheff"], [23, 3, 1, "", "weighted_sum"]], "morl_baselines.common.utils": [[19, 3, 1, "", "linearly_decaying_value"], [19, 3, 1, "", "make_gif"], [19, 3, 1, "", "nearest_neighbors"], [19, 3, 1, "", "reset_wandb_env"], [19, 3, 1, "", "unique_tol"]], "morl_baselines.common.weights": [[24, 3, 1, "", "equally_spaced_weights"], [24, 3, 1, "", "extrema_weights"], [24, 3, 1, "", "random_weights"]], "morl_baselines.multi_policy.capql.capql": [[2, 0, 1, "", "CAPQL"]], "morl_baselines.multi_policy.capql.capql.CAPQL": [[2, 1, 1, "", "eval"], [2, 1, 1, "", "get_config"], [2, 1, 1, "", "load"], [2, 1, 1, "", "save"], [2, 1, 1, "", "train"], [2, 1, 1, "", "update"]], "morl_baselines.multi_policy.envelope.envelope": [[3, 0, 1, "", "Envelope"]], "morl_baselines.multi_policy.envelope.envelope.Envelope": [[3, 1, 1, "", "act"], [3, 1, 1, "", "ddqn_target"], [3, 1, 1, "", "envelope_target"], [3, 1, 1, "", "eval"], [3, 1, 1, "", "get_config"], [3, 1, 1, "", "load"], [3, 1, 1, "", "max_action"], [3, 1, 1, "", "save"], [3, 1, 1, "", "train"], [3, 1, 1, "", "update"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd": [[4, 0, 1, "", "GPIPD"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD": [[4, 1, 1, "", "eval"], [4, 1, 1, "", "get_config"], [4, 1, 1, "", "gpi_action"], [4, 1, 1, "", "load"], [4, 1, 1, "", "max_action"], [4, 1, 1, "", "save"], [4, 1, 1, "", "set_weight_support"], [4, 1, 1, "", "train"], [4, 1, 1, "", "train_iteration"], [4, 1, 1, "", "update"]], "morl_baselines.multi_policy.linear_support.linear_support": [[5, 0, 1, "", "LinearSupport"]], "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport": [[5, 1, 1, "", "add_solution"], [5, 1, 1, "", "compute_corner_weights"], [5, 1, 1, "", "ended"], [5, 1, 1, "", "get_corner_weights"], [5, 1, 1, "", "get_weight_support"], [5, 1, 1, "", "gpi_ls_priority"], [5, 1, 1, "", "is_dominated"], [5, 1, 1, "", "max_scalarized_value"], [5, 1, 1, "", "max_value_lp"], [5, 1, 1, "", "next_weight"], [5, 1, 1, "", "ols_priority"], [5, 1, 1, "", "remove_obsolete_values"], [5, 1, 1, "", "remove_obsolete_weights"]], "morl_baselines.multi_policy.morld.morld": [[6, 0, 1, "", "MORLD"]], "morl_baselines.multi_policy.morld.morld.MORLD": [[6, 1, 1, "", "get_config"], [6, 1, 1, "", "train"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning": [[7, 0, 1, "", "MPMOQLearning"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning": [[7, 1, 1, "", "delete_policies"], [7, 1, 1, "", "eval"], [7, 1, 1, "", "get_config"], [7, 1, 1, "", "max_scalar_q_value"], [7, 1, 1, "", "train"]], "morl_baselines.multi_policy.pareto_q_learning.pql": [[8, 0, 1, "", "PQL"]], "morl_baselines.multi_policy.pareto_q_learning.pql.PQL": [[8, 1, 1, "", "calc_non_dominated"], [8, 1, 1, "", "get_config"], [8, 1, 1, "", "get_local_pcs"], [8, 1, 1, "", "get_q_set"], [8, 1, 1, "", "score_hypervolume"], [8, 1, 1, "", "score_pareto_cardinality"], [8, 1, 1, "", "select_action"], [8, 1, 1, "", "track_policy"], [8, 1, 1, "", "train"]], "morl_baselines.multi_policy.pcn.pcn": [[9, 0, 1, "", "PCN"]], "morl_baselines.multi_policy.pcn.pcn.PCN": [[9, 1, 1, "", "eval"], [9, 1, 1, "", "evaluate"], [9, 1, 1, "", "get_config"], [9, 1, 1, "", "save"], [9, 1, 1, "", "set_desired_return_and_horizon"], [9, 1, 1, "", "train"], [9, 1, 1, "", "update"]], "morl_baselines.multi_policy.pgmorl.pgmorl": [[10, 0, 1, "", "PGMORL"], [10, 0, 1, "", "PerformancePredictor"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL": [[10, 1, 1, "", "get_config"], [10, 1, 1, "", "train"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor": [[10, 1, 1, "", "add"], [10, 1, 1, "", "predict_next_evaluation"]], "morl_baselines.single_policy.esr.eupg": [[13, 0, 1, "", "EUPG"]], "morl_baselines.single_policy.esr.eupg.EUPG": [[13, 1, 1, "", "eval"], [13, 1, 1, "", "get_buffer"], [13, 1, 1, "", "get_config"], [13, 1, 1, "", "get_policy_net"], [13, 1, 1, "", "set_buffer"], [13, 1, 1, "", "set_weights"], [13, 1, 1, "", "train"], [13, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_ppo": [[10, 0, 1, "", "MOPPO"]], "morl_baselines.single_policy.ser.mo_ppo.MOPPO": [[10, 1, 1, "", "change_weights"], [10, 1, 1, "", "eval"], [10, 1, 1, "", "train"], [10, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_q_learning": [[14, 0, 1, "", "MOQLearning"]], "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning": [[14, 1, 1, "", "eval"], [14, 1, 1, "", "get_config"], [14, 1, 1, "", "scalarized_q_values"], [14, 1, 1, "", "train"], [14, 1, 1, "", "update"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "titleterms": {"overview": [0, 26], "multi": [1, 11, 16, 25], "polici": [1, 11, 12], "algorithm": [1, 11, 12, 25], "concav": 2, "augment": 2, "pareto": [2, 8, 9, 21], "q": [2, 3, 8], "learn": [2, 3, 7, 8, 14, 25], "capql": 2, "envelop": 3, "gpi": 4, "priorit": [4, 16], "dyna": 4, "linear": 5, "support": 5, "morl": [6, 25], "d": 6, "mpmoq": 7, "condit": 9, "network": [9, 20], "pgmorl": 10, "applic": 10, "limit": 10, "principl": 10, "moppo": 10, "weight": [10, 24], "gener": 10, "predict": 10, "model": 10, "perform": [11, 22], "assess": 11, "introduct": 11, "metric": 11, "singl": [11, 12], "storag": 11, "benchmark": [11, 25], "script": 11, "refer": 11, "eupg": 13, "moq": 14, "commun": 15, "maintain": 15, "contribut": 15, "acknowledg": 15, "replai": 16, "buffer": 16, "object": [16, 25], "divers": 16, "accru": 16, "reward": 16, "evalu": 17, "hyperparamet": 18, "optim": 18, "miscellan": 19, "neural": 20, "helper": [20, 24], "util": 21, "indic": 22, "scalar": 23, "function": 23, "baselin": 25, "A": 25, "collect": 25, "reinforc": 25, "featur": 25, "cite": 25}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Overview": [[0, "overview"], [26, "overview"]], "Multi-Policy Algorithms": [[1, "multi-policy-algorithms"]], "Concave-Augmented Pareto Q-Learning (CAPQL)": [[2, "concave-augmented-pareto-q-learning-capql"]], "Envelope Q-Learning": [[3, "envelope-q-learning"]], "GPI-Prioritized Dyna": [[4, "gpi-prioritized-dyna"]], "Linear Support": [[5, "linear-support"]], "MORL/D": [[6, "morl-d"]], "MPMOQ Learning": [[7, "mpmoq-learning"]], "Pareto Q-Learning": [[8, "pareto-q-learning"]], "Pareto Conditioned Networks": [[9, "pareto-conditioned-networks"]], "PGMORL": [[10, "pgmorl"], [10, "id1"]], "Applicability and limitations": [[10, "applicability-and-limitations"]], "Principle": [[10, "principle"]], "MOPPO": [[10, "moppo"]], "Weight generator - prediction model": [[10, "weight-generator-prediction-model"]], "Performance assessments": [[11, "performance-assessments"]], "Introduction": [[11, "introduction"]], "Metrics": [[11, "metrics"]], "Single-policy algorithms": [[11, "single-policy-algorithms"]], "Multi-policy algorithms": [[11, "multi-policy-algorithms"]], "Storage": [[11, "storage"]], "Benchmarking script": [[11, "benchmarking-script"]], "Algorithms": [[11, "algorithms"]], "References": [[11, "references"]], "Single-policy Algorithms": [[12, "single-policy-algorithms"]], "EUPG": [[13, "eupg"]], "MOQ-Learning": [[14, "moq-learning"]], "Community": [[15, "community"]], "Maintainers": [[15, "maintainers"]], "Contributing": [[15, "contributing"]], "Acknowledgements": [[15, "acknowledgements"]], "Replay Buffers": [[16, "replay-buffers"]], "Multi-Objective Replay Buffer": [[16, "multi-objective-replay-buffer"]], "Diverse Replay Buffer": [[16, "diverse-replay-buffer"]], "Prioritized Replay Buffer": [[16, "prioritized-replay-buffer"]], "Accrued Reward Replay Buffer": [[16, "accrued-reward-replay-buffer"]], "Evaluations": [[17, "module-morl_baselines.common.evaluation"]], "Hyperparameter optimization": [[18, "hyperparameter-optimization"]], "Miscellaneous": [[19, "module-morl_baselines.common.utils"]], "Neural Networks helpers": [[20, "module-morl_baselines.common.networks"]], "Pareto utils": [[21, "module-morl_baselines.common.pareto"]], "Performance indicators": [[22, "module-morl_baselines.common.performance_indicators"]], "Scalarization functions": [[23, "module-morl_baselines.common.scalarization"]], "Weights helpers": [[24, "module-morl_baselines.common.weights"]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[25, "morl-baselines-a-collection-of-multi-objective-reinforcement-learning-algorithms"]], "Features of MORL-Baselines": [[25, "features-of-morl-baselines"]], "Benchmarks": [[25, "benchmarks"]], "Citing MORL-Baselines": [[25, "citing-morl-baselines"]]}, "indexentries": {"capql (class in morl_baselines.multi_policy.capql.capql)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL"]], "eval() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.eval"]], "get_config() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.get_config"]], "load() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.load"]], "save() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.save"]], "train() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.train"]], "update() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.update"]], "envelope (class in morl_baselines.multi_policy.envelope.envelope)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope"]], "act() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.act"]], "ddqn_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.ddqn_target"]], "envelope_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.envelope_target"]], "eval() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.eval"]], "get_config() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.get_config"]], "load() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.load"]], "max_action() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.max_action"]], "save() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.save"]], "train() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.train"]], "update() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.update"]], "gpipd (class in morl_baselines.multi_policy.gpi_pd.gpi_pd)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD"]], "eval() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.eval"]], "get_config() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.get_config"]], "gpi_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.gpi_action"]], "load() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.load"]], "max_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.max_action"]], "save() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.save"]], "set_weight_support() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.set_weight_support"]], "train() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train"]], "train_iteration() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train_iteration"]], "update() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.update"]], "linearsupport (class in morl_baselines.multi_policy.linear_support.linear_support)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport"]], "add_solution() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.add_solution"]], "compute_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.compute_corner_weights"]], "ended() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ended"]], "get_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_corner_weights"]], "get_weight_support() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_weight_support"]], "gpi_ls_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.gpi_ls_priority"]], "is_dominated() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.is_dominated"]], "max_scalarized_value() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_scalarized_value"]], "max_value_lp() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_value_lp"]], "next_weight() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.next_weight"]], "ols_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ols_priority"]], "remove_obsolete_values() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_values"]], "remove_obsolete_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_weights"]], "morld (class in morl_baselines.multi_policy.morld.morld)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD"]], "get_config() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.get_config"]], "train() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.train"]], "mpmoqlearning (class in morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning"]], "delete_policies() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.delete_policies"]], "eval() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.eval"]], "get_config() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.get_config"]], "max_scalar_q_value() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.max_scalar_q_value"]], "train() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.train"]], "pql (class in morl_baselines.multi_policy.pareto_q_learning.pql)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL"]], "calc_non_dominated() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.calc_non_dominated"]], "get_config() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_config"]], "get_local_pcs() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_local_pcs"]], "get_q_set() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_q_set"]], "score_hypervolume() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_hypervolume"]], "score_pareto_cardinality() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_pareto_cardinality"]], "select_action() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.select_action"]], "track_policy() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.track_policy"]], "train() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.train"]], "pcn (class in morl_baselines.multi_policy.pcn.pcn)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN"]], "eval() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.eval"]], "evaluate() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.evaluate"]], "get_config() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.get_config"]], "save() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.save"]], "set_desired_return_and_horizon() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.set_desired_return_and_horizon"]], "train() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.train"]], "update() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.update"]], "moppo (class in morl_baselines.single_policy.ser.mo_ppo)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO"]], "pgmorl (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL"]], "performancepredictor (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor"]], "add() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.add"]], "change_weights() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.change_weights"]], "eval() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.eval"]], "get_config() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.get_config"]], "predict_next_evaluation() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.predict_next_evaluation"]], "train() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.train"]], "train() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.train"]], "update() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.update"]], "eupg (class in morl_baselines.single_policy.esr.eupg)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG"]], "eval() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.eval"]], "get_buffer() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_buffer"]], "get_config() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_config"]], "get_policy_net() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_policy_net"]], "set_buffer() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.set_buffer"]], "set_weights() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.set_weights"]], "train() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.train"]], "update() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.update"]], "moqlearning (class in morl_baselines.single_policy.ser.mo_q_learning)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning"]], "eval() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.eval"]], "get_config() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.get_config"]], "scalarized_q_values() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.scalarized_q_values"]], "train() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.train"]], "update() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.update"]], "accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer"]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory"]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer"]], "replaybuffer (class in morl_baselines.common.buffer)": [[16, "morl_baselines.common.buffer.ReplayBuffer"]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add"]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.add"]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add"]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add"]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample"]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree"]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup"]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe"]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace"]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get"]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data"]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data"]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error"]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write"]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value"]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full"]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec"]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace"]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample"]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.sample"]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.sample"]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample"]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.sample_obs"]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs"]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances"]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.update"]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities"]], "eval_mo() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.eval_mo"]], "eval_mo_reward_conditioned() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.eval_mo_reward_conditioned"]], "log_all_multi_policy_metrics() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.log_all_multi_policy_metrics"]], "log_episode_info() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.log_episode_info"]], "module": [[17, "module-morl_baselines.common.evaluation"], [19, "module-morl_baselines.common.utils"], [20, "module-morl_baselines.common.networks"], [21, "module-morl_baselines.common.pareto"], [22, "module-morl_baselines.common.performance_indicators"], [23, "module-morl_baselines.common.scalarization"], [24, "module-morl_baselines.common.weights"]], "morl_baselines.common.evaluation": [[17, "module-morl_baselines.common.evaluation"]], "policy_evaluation_mo() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.policy_evaluation_mo"]], "seed_everything() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.seed_everything"]], "linearly_decaying_value() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.linearly_decaying_value"]], "make_gif() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.make_gif"]], "morl_baselines.common.utils": [[19, "module-morl_baselines.common.utils"]], "nearest_neighbors() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.nearest_neighbors"]], "reset_wandb_env() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.reset_wandb_env"]], "unique_tol() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.unique_tol"]], "naturecnn (class in morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.NatureCNN"]], "forward() (morl_baselines.common.networks.naturecnn method)": [[20, "morl_baselines.common.networks.NatureCNN.forward"]], "get_grad_norm() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.get_grad_norm"]], "huber() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.huber"]], "layer_init() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.layer_init"]], "mlp() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.mlp"]], "morl_baselines.common.networks": [[20, "module-morl_baselines.common.networks"]], "polyak_update() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.polyak_update"]], "paretoarchive (class in morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.ParetoArchive"]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[21, "morl_baselines.common.pareto.ParetoArchive.add"]], "filter_convex_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.filter_convex_dominated"]], "filter_pareto_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.filter_pareto_dominated"]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_dominated"]], "get_non_dominated_inds() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_dominated_inds"]], "get_non_pareto_dominated_inds() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_pareto_dominated_inds"]], "morl_baselines.common.pareto": [[21, "module-morl_baselines.common.pareto"]], "cardinality() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.cardinality"]], "expected_utility() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.expected_utility"]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.hypervolume"]], "igd() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.igd"]], "maximum_utility_loss() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.maximum_utility_loss"]], "morl_baselines.common.performance_indicators": [[22, "module-morl_baselines.common.performance_indicators"]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.sparsity"]], "morl_baselines.common.scalarization": [[23, "module-morl_baselines.common.scalarization"]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[23, "morl_baselines.common.scalarization.tchebicheff"]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[23, "morl_baselines.common.scalarization.weighted_sum"]], "equally_spaced_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.equally_spaced_weights"]], "extrema_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.extrema_weights"]], "morl_baselines.common.weights": [[24, "module-morl_baselines.common.weights"]], "random_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.random_weights"]]}})