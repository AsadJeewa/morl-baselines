Search.setIndex({"docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/envelope", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/ols", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pgmorl", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "index", "quickstart/overview"], "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/envelope.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/ols.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pgmorl.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "index.md", "quickstart/overview.md"], "titles": ["Overview", "Multi-Policy Algorithms", "Envelope Q-Learning", "MPMOQ Learning", "OLS", "Pareto Q-Learning", "PGMORL", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "terms": {"morl": [0, 10, 18], "baselin": [0, 10, 18], "contain": [0, 11, 17, 18], "multipl": [0, 11], "implement": [0, 10, 11, 17, 18], "multi": [0, 13, 15, 18], "object": [0, 15], "reinforc": [0, 11, 13], "learn": [0, 10, 11, 13], "algorithm": [0, 10, 11, 15, 18], "The": [0, 11, 13, 14, 18], "follow": [0, 11, 13, 17, 18], "tabl": 0, "list": [0, 11, 13, 15], "ar": [0, 10, 11, 15, 17], "current": [0, 10, 11, 13, 15], "algo": 0, "singl": [0, 17, 18], "polici": [0, 17, 18], "esr": [0, 11, 17, 18], "ser": [0, 17, 18], "observ": [0, 11, 13], "space": 0, "action": [0, 11], "paper": [0, 13, 17], "envelop": 0, "q": [0, 10], "continu": 0, "discret": 0, "pgmorl": [0, 15], "supplementari": 0, "materi": 0, "pareto": [0, 10, 15, 17], "mo": [0, 17, 18], "mpmoqlearn": 0, "outer": 0, "loop": 0, "moql": 0, "optimist": 0, "linear": 0, "support": 0, "ol": 0, "section": 0, "3": 0, "thesi": 0, "expect": 0, "util": [0, 13, 17], "gradient": 0, "eupg": [0, 10], "we": [10, 11, 15, 17], "have": [10, 14, 17], "discord": 10, "server": 10, "where": 10, "you": 10, "can": 10, "ask": 10, "question": [10, 14], "get": [10, 11], "help": 10, "repositori": [10, 17], "join": 10, "here": 10, "i": [10, 11, 13, 14, 15, 16, 17, 18], "florian": [10, 17], "felten": [10, 17], "ffelten": 10, "luca": [10, 17], "n": [10, 11, 17], "alegr": [10, 17], "lucasalegr": [10, 17], "thi": [10, 11, 13, 14, 16, 17, 18], "open": 10, "alwai": [10, 16], "happi": 10, "receiv": 10, "new": [10, 11], "bug": 10, "fix": 10, "featur": [10, 13], "If": [10, 11], "want": 10, "our": 10, "discuss": 10, "your": 10, "idea": 10, "u": 10, "also": 10, "an": [10, 13], "issu": 10, "pull": 10, "request": 10, "directli": 10, "asid": 10, "from": [10, 11, 13, 15, 17], "main": [10, 11], "contributor": 10, "mani": 10, "peopl": 10, "who": 10, "project": 10, "variou": 10, "wai": [10, 11], "would": 10, "like": 10, "thank": 10, "them": 10, "all": [10, 11, 14, 17, 18], "willem": 10, "r\u00f6pke": 10, "hi": 10, "wilrop": 10, "deni": 10, "steckelmach": 10, "conor": 10, "f": 10, "hay": 10, "provid": [10, 11, 14, 17], "origin": [10, 17], "avail": [11, 17], "librari": [11, 17], "These": 11, "below": 11, "class": [11, 13, 14], "morl_baselin": [11, 13, 14, 15, 16, 17], "common": [11, 13, 14, 15, 16, 18], "replaybuff": 11, "obs_shap": 11, "action_dim": 11, "rew_dim": 11, "1": 11, "max_siz": 11, "100000": 11, "obs_dtyp": 11, "numpi": [11, 16, 17], "float32": 11, "action_dtyp": 11, "add": [11, 14], "ob": 11, "next_ob": 11, "done": 11, "experi": [11, 17], "paramet": [11, 13, 14, 15, 16, 17], "next": 11, "get_all_data": 11, "max_sampl": 11, "none": 11, "data": 11, "maximum": 11, "specifi": 11, "number": [11, 13], "sampl": 11, "return": [11, 14, 15, 16, 17], "A": 11, "tupl": 11, "batch_siz": 11, "replac": 11, "true": 11, "use_c": 11, "fals": 11, "to_tensor": 11, "devic": 11, "batch": 11, "size": 11, "whether": 11, "us": [11, 13, 18], "cer": 11, "convert": 11, "pytorch": [11, 17], "tensor": [11, 13], "sample_ob": 11, "diverse_buff": 11, "diversememori": 11, "main_capac": 11, "int": [11, 13, 15, 16], "sec_capac": 11, "0": 11, "trace_divers": 11, "bool": [11, 15], "crowding_divers": 11, "value_funct": 11, "function": [11, 13, 14, 17], "lambda": 11, "e": [11, 17], "float": [11, 15, 16], "01": 11, "2": 11, "integr": 11, "secondari": 11, "code": [11, 14, 17], "extract": 11, "http": [11, 14, 17], "github": [11, 17], "com": [11, 14, 17], "axelabel": 11, "dynmorl": 11, "error": 11, "trace_id": 11, "pred_idx": 11, "tree_id": 11, "prioriti": 11, "proport": 11, "its": 11, "other": [11, 17], "same": 11, "id": 11, "treat": 11, "trace": 11, "when": 11, "determin": 11, "transit": 11, "store": 11, "": [11, 17, 18], "identifi": 11, "default": 11, "tree": 11, "which": [11, 13, 17], "relev": 11, "index": 11, "node": 11, "wa": 11, "add_sampl": 11, "write": 11, "previou": 11, "dictionari": 11, "each": [11, 13, 15, 16], "add_tre": 11, "dupe": 11, "trg_i": 11, "src_i": 11, "copi": 11, "target": 11, "sourc": [11, 14], "extract_trac": 11, "start": 11, "end": 11, "posit": 11, "indic": 11, "given": 11, "method": 11, "those": 11, "arrai": [11, 17], "get_data": 11, "include_indic": 11, "includ": 11, "get_error": 11, "idx": 11, "correspond": 11, "updat": 11, "get_sec_writ": 11, "secondary_trac": 11, "reserved_idx": 11, "find": 11, "free": 11, "spot": 11, "memori": [11, 14], "recurs": 11, "remov": [11, 14], "past": 11, "low": 11, "crowd": 11, "distanc": [11, 15], "get_trace_valu": 11, "trace_tupl": 11, "appli": 11, "comput": [11, 15], "valu": [11, 15, 16], "main_mem_is_ful": 11, "becaus": 11, "circular": 11, "fill": 11, "check": 11, "suffici": 11, "know": 11, "full": 11, "move_to_sec": 11, "move": 11, "span": 11, "remove_trac": 11, "whose": 11, "should": 11, "pair": 11, "sec_dist": 11, "give": 11, "set": [11, 14, 15, 18], "prioritized_buff": 11, "prioritizedreplaybuff": 11, "min_prior": 11, "1e": 11, "05": 11, "update_prior": 11, "accrued_reward_buff": 11, "accruedrewardreplaybuff": 11, "action_shap": 11, "accrued_reward": 11, "cleanup": 11, "whole": 11, "order": 11, "element": [11, 14], "naturecnn": 13, "observation_shap": 13, "ndarrai": [13, 14, 15, 16], "features_dim": 13, "512": 13, "cnn": 13, "dqn": 13, "natur": 13, "mnih": 13, "volodymyr": 13, "et": 13, "al": 13, "human": 13, "level": 13, "control": 13, "through": 13, "deep": 13, "518": 13, "7540": 13, "2015": 13, "529": 13, "533": 13, "forward": 13, "predict": 13, "mlp": 13, "input_dim": 13, "output_dim": 13, "net_arch": 13, "type": 13, "activation_fn": 13, "torch": 13, "nn": 13, "modul": 13, "activ": 13, "relu": 13, "sequenti": 13, "creat": 13, "layer": 13, "perceptron": 13, "collect": 13, "fulli": 13, "connect": 13, "dimens": [13, 16], "input": [13, 14], "vector": [13, 14, 15, 16], "output": 13, "architectur": 13, "net": [13, 18], "It": [13, 16, 17], "repres": 13, "unit": 13, "per": 13, "length": 13, "after": 13, "paretoarch": 14, "archiv": 14, "candid": 14, "evalu": 14, "ineffici": 14, "point": [14, 15, 16], "get_non_domin": 14, "non": 14, "domin": [14, 16], "subset": 14, "stackoverflow": 14, "32791911": 14, "fast": 14, "calcul": 14, "front": [14, 15], "python": 14, "answer": 14, "wrong": 14, "import": 14, "chang": 14, "been": [14, 17], "made": [14, 15], "rl": 15, "mostli": 15, "reli": [15, 16], "pymoo": 15, "some": 15, "customli": 15, "performance_ind": 15, "hypervolum": 15, "ref_point": 15, "union": 15, "_supportsarrai": 15, "dtype": 15, "_nestedsequ": 15, "complex": 15, "str": 15, "byte": 15, "metric": 15, "refer": [15, 16], "np": 15, "sparsiti": 15, "basic": 15, "averag": 15, "between": 15, "tchebicheff": 16, "tau": 16, "reward_dim": 16, "requir": 16, "automat": [16, 17], "adapt": 16, "best": 16, "seen": 16, "so": 16, "far": 16, "compon": 16, "reward": [16, 17], "sure": 16, "callabl": 16, "weighted_sum": 16, "weight": [16, 17], "sum": 16, "dot": 16, "product": 16, "aim": 17, "reliabl": 17, "strictli": 17, "gymnasium": 17, "api": 17, "differ": 17, "standard": 17, "onli": 17, "environ": [17, 18], "For": 17, "detail": [17, 18], "mdp": 17, "momdp": 17, "definit": 17, "suggest": 17, "read": 17, "practic": 17, "guid": 17, "plan": 17, "under": 17, "both": 17, "criteria": 17, "perform": 17, "report": 17, "bias": 17, "dashboard": 17, "lint": 17, "format": 17, "enforc": 17, "pre": 17, "commit": 17, "hook": 17, "well": 17, "document": [17, 18], "g": 17, "prune": 17, "buffer": [17, 18], "etc": [17, 18], "hyper": 17, "optim": 17, "test": 17, "against": 17, "ones": 17, "misc": 17, "author": 17, "titl": 17, "year": 17, "2022": 17, "publish": 17, "journal": 17, "howpublish": 17, "url": 17, "As": 18, "much": 18, "possibl": 18, "repo": 18, "tri": 18, "file": 18, "rule": 18, "structur": 18, "exampl": 18, "gym": 18, "recur": 18, "concept": 18, "replai": 18, "neural": 18, "see": 18, "more": 18, "multi_polici": 18, "single_polici": 18}, "objects": {"morl_baselines.common.accrued_reward_buffer": [[11, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[11, 1, 1, "", "add"], [11, 1, 1, "", "cleanup"], [11, 1, 1, "", "get_all_data"], [11, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[11, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[11, 1, 1, "", "add"], [11, 1, 1, "", "get_all_data"], [11, 1, 1, "", "sample"], [11, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[11, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[11, 1, 1, "", "add"], [11, 1, 1, "", "add_sample"], [11, 1, 1, "", "add_tree"], [11, 1, 1, "", "dupe"], [11, 1, 1, "", "extract_trace"], [11, 1, 1, "", "get"], [11, 1, 1, "", "get_data"], [11, 1, 1, "", "get_error"], [11, 1, 1, "", "get_sec_write"], [11, 1, 1, "", "get_trace_value"], [11, 1, 1, "", "main_mem_is_full"], [11, 1, 1, "", "move_to_sec"], [11, 1, 1, "", "remove_trace"], [11, 1, 1, "", "sample"], [11, 1, 1, "", "sec_distances"], [11, 1, 1, "", "update"]], "morl_baselines.common": [[13, 2, 0, "-", "networks"], [14, 2, 0, "-", "pareto"], [15, 2, 0, "-", "performance_indicators"], [16, 2, 0, "-", "scalarization"]], "morl_baselines.common.networks": [[13, 0, 1, "", "NatureCNN"], [13, 3, 1, "", "mlp"]], "morl_baselines.common.networks.NatureCNN": [[13, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[14, 0, 1, "", "ParetoArchive"], [14, 3, 1, "", "get_non_dominated"]], "morl_baselines.common.pareto.ParetoArchive": [[14, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[15, 3, 1, "", "hypervolume"], [15, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[11, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[11, 1, 1, "", "add"], [11, 1, 1, "", "get_all_data"], [11, 1, 1, "", "sample"], [11, 1, 1, "", "sample_obs"], [11, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[16, 3, 1, "", "tchebicheff"], [16, 3, 1, "", "weighted_sum"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "titleterms": {"overview": [0, 18], "multi": [1, 11, 17], "polici": [1, 7], "algorithm": [1, 7, 17], "envelop": 2, "q": [2, 5], "learn": [2, 3, 5, 9, 17], "mpmoq": 3, "ol": 4, "pareto": [5, 14], "pgmorl": 6, "singl": 7, "eupg": 8, "moq": 9, "commun": 10, "maintain": 10, "contribut": 10, "acknowledg": 10, "replai": 11, "buffer": 11, "object": [11, 17], "divers": 11, "priorit": 11, "accru": 11, "reward": 11, "miscellan": 12, "neural": 13, "network": 13, "helper": 13, "util": 14, "perform": 15, "indic": 15, "scalar": 16, "function": 16, "morl": 17, "baselin": 17, "A": 17, "collect": 17, "reinforc": 17, "featur": 17, "cite": 17}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Overview": [[0, "overview"], [18, "overview"]], "Multi-Policy Algorithms": [[1, "multi-policy-algorithms"]], "Envelope Q-Learning": [[2, "envelope-q-learning"]], "MPMOQ Learning": [[3, "mpmoq-learning"]], "OLS": [[4, "ols"]], "Pareto Q-Learning": [[5, "pareto-q-learning"]], "PGMORL": [[6, "pgmorl"]], "Single-policy Algorithms": [[7, "single-policy-algorithms"]], "EUPG": [[8, "eupg"]], "MOQ-Learning": [[9, "moq-learning"]], "Community": [[10, "community"]], "Maintainers": [[10, "maintainers"]], "Contributing": [[10, "contributing"]], "Acknowledgements": [[10, "acknowledgements"]], "Replay Buffers": [[11, "replay-buffers"]], "Multi-Objective Replay Buffer": [[11, "multi-objective-replay-buffer"]], "Diverse Replay Buffer": [[11, "diverse-replay-buffer"]], "Prioritized Replay Buffer": [[11, "prioritized-replay-buffer"]], "Accrued Reward Replay Buffer": [[11, "accrued-reward-replay-buffer"]], "Miscellaneous": [[12, "miscellaneous"]], "Neural Networks helpers": [[13, "module-morl_baselines.common.networks"]], "Pareto utils": [[14, "module-morl_baselines.common.pareto"]], "Performance indicators": [[15, "module-morl_baselines.common.performance_indicators"]], "Scalarization functions": [[16, "module-morl_baselines.common.scalarization"]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[17, "morl-baselines-a-collection-of-multi-objective-reinforcement-learning-algorithms"]], "Features of MORL-Baselines": [[17, "features-of-morl-baselines"]], "Citing MORL-Baselines": [[17, "citing-morl-baselines"]]}, "indexentries": {"accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[11, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer"]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory"]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer"]], "replaybuffer (class in morl_baselines.common.buffer)": [[11, "morl_baselines.common.buffer.ReplayBuffer"]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[11, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add"]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[11, "morl_baselines.common.buffer.ReplayBuffer.add"]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.add"]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add"]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample"]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree"]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[11, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup"]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe"]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace"]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.get"]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[11, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[11, "morl_baselines.common.buffer.ReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data"]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data"]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error"]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write"]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value"]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full"]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec"]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace"]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[11, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample"]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[11, "morl_baselines.common.buffer.ReplayBuffer.sample"]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.sample"]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample"]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[11, "morl_baselines.common.buffer.ReplayBuffer.sample_obs"]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs"]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances"]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[11, "morl_baselines.common.diverse_buffer.DiverseMemory.update"]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[11, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities"]], "naturecnn (class in morl_baselines.common.networks)": [[13, "morl_baselines.common.networks.NatureCNN"]], "forward() (morl_baselines.common.networks.naturecnn method)": [[13, "morl_baselines.common.networks.NatureCNN.forward"]], "mlp() (in module morl_baselines.common.networks)": [[13, "morl_baselines.common.networks.mlp"]], "module": [[13, "module-morl_baselines.common.networks"], [14, "module-morl_baselines.common.pareto"], [15, "module-morl_baselines.common.performance_indicators"], [16, "module-morl_baselines.common.scalarization"]], "morl_baselines.common.networks": [[13, "module-morl_baselines.common.networks"]], "paretoarchive (class in morl_baselines.common.pareto)": [[14, "morl_baselines.common.pareto.ParetoArchive"]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[14, "morl_baselines.common.pareto.ParetoArchive.add"]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[14, "morl_baselines.common.pareto.get_non_dominated"]], "morl_baselines.common.pareto": [[14, "module-morl_baselines.common.pareto"]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[15, "morl_baselines.common.performance_indicators.hypervolume"]], "morl_baselines.common.performance_indicators": [[15, "module-morl_baselines.common.performance_indicators"]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[15, "morl_baselines.common.performance_indicators.sparsity"]], "morl_baselines.common.scalarization": [[16, "module-morl_baselines.common.scalarization"]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[16, "morl_baselines.common.scalarization.tchebicheff"]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[16, "morl_baselines.common.scalarization.weighted_sum"]]}})